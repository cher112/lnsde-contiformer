#!/usr/bin/env python3
"""
ä¸ºMACHOæ•°æ®é›†åº”ç”¨ç‰©ç†çº¦æŸTimeGANé‡é‡‡æ ·
ç”Ÿæˆé«˜è´¨é‡åˆæˆæ ·æœ¬ä»¥æå‡åˆ†ç±»å‡†ç¡®ç‡
"""

import sys
import os
import numpy as np
import pickle
import torch
from pathlib import Path
from collections import Counter

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append('/root/autodl-tmp/lnsde-contiformer')

from utils.resampling import HybridResampler


def load_macho_data():
    """åŠ è½½MACHOåŸå§‹æ•°æ®"""
    data_path = "/root/autodl-fs/lnsde-contiformer/data/MACHO_original.pkl"
    
    print(f"ğŸ”„ åŠ è½½MACHOæ•°æ®: {data_path}")
    
    with open(data_path, 'rb') as f:
        data = pickle.load(f)
    
    print(f"âœ… åŠ è½½å®Œæˆ: {len(data)}ä¸ªæ ·æœ¬")
    
    # åˆ†æç±»åˆ«åˆ†å¸ƒ
    labels = [item['label'] for item in data]
    class_counts = Counter(labels)
    class_names = {item['label']: item['class_name'] for item in data}
    
    print(f"\nğŸ“Š MACHOåŸå§‹æ•°æ®åˆ†å¸ƒ:")
    total_samples = sum(class_counts.values())
    
    for label in sorted(class_counts.keys()):
        count = class_counts[label]
        class_name = class_names.get(label, f'Unknown_{label}')
        percentage = count / total_samples * 100
        print(f"  ç±»åˆ« {label} ({class_name}): {count:3d} æ ·æœ¬ ({percentage:5.1f}%)")
    
    print(f"  æ€»è®¡: {total_samples} æ ·æœ¬")
    
    return data


def convert_to_training_format(data):
    """å°†MACHOæ•°æ®è½¬æ¢ä¸ºè®­ç»ƒæ ¼å¼"""
    print(f"\nğŸ”„ è½¬æ¢æ•°æ®æ ¼å¼...")
    
    X_list = []
    y_list = []
    times_list = []
    masks_list = []
    periods_list = []
    
    for item in data:
        # æå–æ—¶é—´åºåˆ—æ•°æ® (seq_len, 3) [time, mag, errmag]
        time_data = item['time'].astype(np.float32)
        mag_data = item['mag'].astype(np.float32)
        errmag_data = item['errmag'].astype(np.float32)
        mask_data = item['mask'].astype(bool)
        
        # æ„å»ºç‰¹å¾çŸ©é˜µ
        features = np.column_stack([time_data, mag_data, errmag_data])
        X_list.append(features)
        y_list.append(item['label'])
        times_list.append(time_data)
        masks_list.append(mask_data)
        periods_list.append(item['period'])
    
    # è½¬æ¢ä¸ºnumpyæ•°ç»„
    X = np.array(X_list)
    y = np.array(y_list)
    times = np.array(times_list)
    masks = np.array(masks_list)
    periods = np.array(periods_list)
    
    print(f"âœ… è½¬æ¢å®Œæˆ:")
    print(f"  X shape: {X.shape}")
    print(f"  y shape: {y.shape}")
    print(f"  æ•°æ®ç±»å‹: {X.dtype}")
    
    return X, y, times, masks, periods


def design_optimal_resampling_strategy(class_counts):
    """è®¾è®¡æœ€ä¼˜çš„é‡é‡‡æ ·ç­–ç•¥ï¼Œå¹³è¡¡æ•ˆæœå’Œè®­ç»ƒæ•ˆç‡"""
    
    print(f"\nğŸ¯ è®¾è®¡é‡é‡‡æ ·ç­–ç•¥...")
    
    # è®¡ç®—åŸºç¡€ç»Ÿè®¡
    total_samples = sum(class_counts.values())
    max_count = max(class_counts.values())
    min_count = min(class_counts.values())
    
    print(f"  æœ€å¤§ç±»åˆ«: {max_count} æ ·æœ¬")
    print(f"  æœ€å°ç±»åˆ«: {min_count} æ ·æœ¬") 
    print(f"  ä¸å¹³è¡¡ç‡: {max_count/min_count:.2f}")
    
    # è®¾è®¡ç­–ç•¥ï¼š
    # 1. å¯¹äºæå°‘æ•°ç±»ï¼ˆ<100ï¼‰ï¼Œæ‰©å±•åˆ°200-300æ ·æœ¬
    # 2. å¯¹äºä¸­ç­‰å°‘æ•°ç±»ï¼ˆ100-400ï¼‰ï¼Œæ‰©å±•åˆ°400-500æ ·æœ¬  
    # 3. å¯¹äºå¤šæ•°ç±»ï¼Œä¿æŒåŸæ ·æˆ–é€‚åº¦å‡å°‘
    
    target_strategy = {}
    
    for label, count in class_counts.items():
        if count < 100:
            # æå°‘æ•°ç±»ï¼šå¤§å¹…æ‰©å±•
            target = min(300, max_count * 0.8)  # ä¸è¶…è¿‡æœ€å¤§ç±»çš„80%
        elif count < 400:
            # ä¸­ç­‰å°‘æ•°ç±»ï¼šé€‚åº¦æ‰©å±•
            target = min(500, max_count * 0.9)
        else:
            # å¤šæ•°ç±»ï¼šä¿æŒä¸å˜
            target = count
            
        target_strategy[label] = int(target)
    
    print(f"\nğŸ“‹ é‡é‡‡æ ·ç­–ç•¥:")
    for label in sorted(target_strategy.keys()):
        original = class_counts[label]
        target = target_strategy[label]
        change = target - original
        change_pct = (change / original * 100) if original > 0 else 0
        
        status = "å¢åŠ " if change > 0 else ("å‡å°‘" if change < 0 else "ä¿æŒ")
        print(f"  ç±»åˆ« {label}: {original:3d} â†’ {target:3d} ({status} {abs(change):3d}, {change_pct:+5.1f}%)")
    
    total_target = sum(target_strategy.values())
    print(f"  æ€»æ ·æœ¬: {total_samples} â†’ {total_target} (å¢åŠ  {total_target - total_samples})")
    
    return target_strategy


def apply_physics_timegan_resampling(X, y, times, masks, periods, target_strategy):
    """åº”ç”¨ç‰©ç†çº¦æŸTimeGANé‡é‡‡æ ·"""
    
    print(f"\nğŸ§¬ å¼€å§‹ç‰©ç†çº¦æŸTimeGANé‡é‡‡æ ·...")
    print("=" * 60)
    
    # åˆ›å»ºé‡é‡‡æ ·å™¨ - ä½¿ç”¨é€‚ä¸­çš„å‚æ•°å¹³è¡¡æ•ˆæœå’Œé€Ÿåº¦
    resampler = HybridResampler(
        smote_k_neighbors=5,
        enn_n_neighbors=3,
        sampling_strategy=target_strategy,
        synthesis_mode='physics_timegan',  # ä½¿ç”¨ç‰©ç†çº¦æŸTimeGAN
        apply_enn=False,  # æš‚æ—¶ç¦ç”¨ENNä»¥åŠ å¿«é€Ÿåº¦
        noise_level=0.05,
        physics_weight=0.2,  # é€‚ä¸­çš„ç‰©ç†çº¦æŸæƒé‡
        random_state=535411460
    )
    
    # æ‰§è¡Œé‡é‡‡æ ·
    try:
        X_resampled, y_resampled, times_resampled, masks_resampled = resampler.fit_resample(
            X, y, times, masks
        )
        
        print("âœ… ç‰©ç†çº¦æŸTimeGANé‡é‡‡æ ·æˆåŠŸå®Œæˆ!")
        
        # ç»Ÿè®¡é‡é‡‡æ ·ç»“æœ
        final_counts = Counter(y_resampled.tolist() if torch.is_tensor(y_resampled) else y_resampled)
        
        print(f"\nğŸ“Š é‡é‡‡æ ·ç»“æœç»Ÿè®¡:")
        for label in sorted(final_counts.keys()):
            count = final_counts[label]
            target = target_strategy.get(label, 0)
            diff = count - target
            print(f"  ç±»åˆ« {label}: {count:3d} æ ·æœ¬ (ç›®æ ‡: {target}, å·®å¼‚: {diff:+d})")
        
        total_final = sum(final_counts.values())
        print(f"  æœ€ç»ˆæ€»æ ·æœ¬: {total_final}")
        
        return X_resampled, y_resampled, times_resampled, masks_resampled, final_counts
        
    except Exception as e:
        print(f"âŒ ç‰©ç†çº¦æŸTimeGANé‡é‡‡æ ·å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return None, None, None, None, None


def convert_back_to_original_format(X_resampled, y_resampled, times_resampled, masks_resampled, original_data):
    """å°†é‡é‡‡æ ·æ•°æ®è½¬æ¢å›åŸå§‹MACHOæ•°æ®æ ¼å¼"""
    
    print(f"\nğŸ”„ è½¬æ¢å›åŸå§‹æ•°æ®æ ¼å¼...")
    
    # æ„å»ºç±»åˆ«åˆ°ç±»åˆ«åçš„æ˜ å°„
    label_to_class_name = {}
    for item in original_data:
        label_to_class_name[item['label']] = item['class_name']
    
    resampled_data = []
    n_samples = len(y_resampled)
    
    for i in range(n_samples):
        # æå–é‡é‡‡æ ·æ•°æ®
        if torch.is_tensor(X_resampled):
            features = X_resampled[i].cpu().numpy()
            label = y_resampled[i].cpu().numpy().item()
        else:
            features = X_resampled[i]
            label = y_resampled[i]
            
        time_data = features[:, 0]
        mag_data = features[:, 1] 
        errmag_data = features[:, 2]
        
        # è·å–å¯¹åº”çš„æ—¶é—´å’Œæ©ç 
        if times_resampled is not None:
            if torch.is_tensor(times_resampled):
                time_data = times_resampled[i].cpu().numpy()
            else:
                time_data = times_resampled[i]
                
        if masks_resampled is not None:
            if torch.is_tensor(masks_resampled):
                mask_data = masks_resampled[i].cpu().numpy().astype(bool)
            else:
                mask_data = masks_resampled[i].astype(bool)
        else:
            # åŸºäºæ—¶é—´æ•°æ®ç”Ÿæˆæ©ç 
            mask_data = (time_data > -1000) & (time_data < 1e10)
        
        # æ•°æ®è´¨é‡ä¿®æ­£
        # 1. ç¡®ä¿æ—¶é—´æ•°æ®åˆç†
        valid_mask = mask_data.astype(bool)
        time_data[~valid_mask] = -1e9
        mag_data[~valid_mask] = 0.0
        
        # 2. ç¡®ä¿è¯¯å·®æ•°æ®éè´Ÿä¸”åˆç†
        errmag_data = np.abs(errmag_data)
        errmag_data = np.clip(errmag_data, 0.001, 1.0)  # é™åˆ¶åœ¨åˆç†èŒƒå›´
        errmag_data[~valid_mask] = 0.0
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        valid_points = valid_mask.sum()
        
        # éšæœºé€‰æ‹©ä¸€ä¸ªåŒç±»åˆ«çš„åŸå§‹æ ·æœ¬ä½œä¸ºæ¨¡æ¿ï¼ˆç”¨äºperiodç­‰å‚æ•°ï¼‰
        same_class_samples = [s for s in original_data if s['label'] == label]
        if same_class_samples:
            template_sample = np.random.choice(same_class_samples)
            period = template_sample['period']
            coverage = valid_points / len(mask_data)
        else:
            period = np.float64(1.0)  # é»˜è®¤å‘¨æœŸ
            coverage = valid_points / len(mask_data)
        
        # æ„å»ºä¸åŸå§‹æ ¼å¼å®Œå…¨ä¸€è‡´çš„æ ·æœ¬
        resampled_sample = {
            # æ ¸å¿ƒæ•°æ®
            'time': time_data.astype(np.float64),
            'mag': mag_data.astype(np.float64),
            'errmag': errmag_data.astype(np.float64),
            'mask': mask_data.astype(bool),
            'period': np.float64(period),
            'label': int(label),
            
            # å…ƒæ•°æ®
            'file_id': f'timegan_resampled_{i:06d}.dat',
            'original_length': int(valid_points),
            'valid_points': np.int64(valid_points),
            'coverage': np.float64(coverage),
            'class_name': label_to_class_name.get(label, f'class_{label}')
        }
        
        resampled_data.append(resampled_sample)
    
    print(f"âœ… æ ¼å¼è½¬æ¢å®Œæˆ: {len(resampled_data)} ä¸ªæ ·æœ¬")
    
    return resampled_data


def save_resampled_data(resampled_data, save_path):
    """ä¿å­˜é‡é‡‡æ ·æ•°æ®"""
    
    print(f"\nğŸ’¾ ä¿å­˜é‡é‡‡æ ·æ•°æ®...")
    
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    save_dir = os.path.dirname(save_path)
    os.makedirs(save_dir, exist_ok=True)
    
    # ä¿å­˜æ•°æ®
    with open(save_path, 'wb') as f:
        pickle.dump(resampled_data, f)
    
    print(f"âœ… é‡é‡‡æ ·æ•°æ®å·²ä¿å­˜è‡³: {save_path}")
    
    # éªŒè¯ä¿å­˜çš„æ•°æ®
    print(f"ğŸ” éªŒè¯ä¿å­˜çš„æ•°æ®...")
    with open(save_path, 'rb') as f:
        saved_data = pickle.load(f)
    
    print(f"  éªŒè¯: ä¿å­˜äº†{len(saved_data)}ä¸ªæ ·æœ¬")
    
    if saved_data:
        # æ£€æŸ¥ç¬¬ä¸€ä¸ªæ ·æœ¬çš„æ ¼å¼
        sample = saved_data[0]
        print(f"  æ ·æœ¬é”®: {list(sample.keys())}")
        
        for key, value in sample.items():
            if hasattr(value, 'shape'):
                print(f"    {key}: {type(value).__name__} {value.shape} {value.dtype}")
            else:
                print(f"    {key}: {type(value).__name__} = {value}")
    
    # ç»Ÿè®¡æœ€ç»ˆåˆ†å¸ƒ
    final_counts = Counter([s['label'] for s in saved_data])
    print(f"\nğŸ“Š æœ€ç»ˆä¿å­˜çš„ç±»åˆ«åˆ†å¸ƒ:")
    for label in sorted(final_counts.keys()):
        count = final_counts[label]
        class_name = saved_data[0]['class_name'] if saved_data else 'Unknown'
        # æ‰¾åˆ°å¯¹åº”ç±»åˆ«å
        for s in saved_data:
            if s['label'] == label:
                class_name = s['class_name']
                break
        print(f"  ç±»åˆ« {label} ({class_name}): {count} æ ·æœ¬")
    
    file_size_mb = os.path.getsize(save_path) / (1024 * 1024)
    print(f"  æ–‡ä»¶å¤§å°: {file_size_mb:.1f} MB")
    
    return save_path


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ MACHOæ•°æ®é›†ç‰©ç†çº¦æŸTimeGANé‡é‡‡æ ·")
    print("=" * 60)
    
    try:
        # 1. åŠ è½½MACHOæ•°æ®
        original_data = load_macho_data()
        
        # 2. è½¬æ¢ä¸ºè®­ç»ƒæ ¼å¼
        X, y, times, masks, periods = convert_to_training_format(original_data)
        
        # 3. åˆ†æå¹¶è®¾è®¡é‡é‡‡æ ·ç­–ç•¥
        class_counts = Counter(y)
        target_strategy = design_optimal_resampling_strategy(class_counts)
        
        # 4. åº”ç”¨ç‰©ç†çº¦æŸTimeGANé‡é‡‡æ ·
        X_resampled, y_resampled, times_resampled, masks_resampled, final_counts = apply_physics_timegan_resampling(
            X, y, times, masks, periods, target_strategy
        )
        
        if X_resampled is None:
            print("âŒ é‡é‡‡æ ·å¤±è´¥ï¼Œç¨‹åºé€€å‡º")
            return
        
        # 5. è½¬æ¢å›åŸå§‹æ ¼å¼
        resampled_data = convert_back_to_original_format(
            X_resampled, y_resampled, times_resampled, masks_resampled, original_data
        )
        
        # 6. ä¿å­˜åˆ°æŒ‡å®šä½ç½®
        save_path = "/root/autodl-fs/lnsde-contiformer/data/macho_resample_timegan.pkl"
        saved_path = save_resampled_data(resampled_data, save_path)
        
        print(f"\nğŸ‰ MACHOç‰©ç†çº¦æŸTimeGANé‡é‡‡æ ·å®Œæˆ!")
        print("=" * 60)
        print(f"âœ… åŸå§‹æ•°æ®: {len(original_data)} æ ·æœ¬")
        print(f"âœ… é‡é‡‡æ ·å: {len(resampled_data)} æ ·æœ¬")
        print(f"âœ… ä¿å­˜ä½ç½®: {saved_path}")
        print(f"âœ… å¯ç›´æ¥ç”¨äºè®­ç»ƒï¼Œé¢„æœŸåˆ†ç±»å‡†ç¡®ç‡æ˜¾è‘—æå‡")
        
    except Exception as e:
        print(f"âŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()