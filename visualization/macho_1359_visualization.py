#!/usr/bin/env python3
"""
MACHO 1359æ•°æ®é›†è®­ç»ƒå¯è§†åŒ–è„šæœ¬
åŸºäºåˆå¹¶çš„æ—¥å¿—æ–‡ä»¶ç”Ÿæˆè®­ç»ƒæ›²çº¿ï¼ˆepochs 21-50ï¼‰
"""

import json
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import seaborn as sns
import os

def configure_chinese_font():
    """é…ç½®ä¸­æ–‡å­—ä½“æ˜¾ç¤º"""
    # æ·»åŠ å­—ä½“åˆ°matplotlibç®¡ç†å™¨
    fm.fontManager.addfont('/usr/share/fonts/truetype/wqy/wqy-zenhei.ttc')
    fm.fontManager.addfont('/usr/share/fonts/truetype/wqy/wqy-microhei.ttc')
    
    # è®¾ç½®ä¸­æ–‡å­—ä½“ä¼˜å…ˆçº§åˆ—è¡¨
    plt.rcParams['font.sans-serif'] = ['WenQuanYi Zen Hei', 'WenQuanYi Micro Hei', 'DejaVu Sans']
    plt.rcParams['axes.unicode_minus'] = False
    
    return True

def setup_seaborn_style():
    """è®¾ç½®Seabornç§‘ç ”ç»˜å›¾é£æ ¼"""
    configure_chinese_font()
    
    sns.set_style("whitegrid", {
        "axes.edgecolor": "0.15",
        "axes.linewidth": 1.25,
        "axes.spines.left": True,
        "axes.spines.bottom": True,
        "axes.spines.top": False,
        "axes.spines.right": False,
        "grid.linewidth": 0.8,
        "grid.color": "0.9"
    })
    
    colors = ['#2E86AB', '#A23B72', '#F18F01', '#C73E1D', '#7209B7']
    sns.set_palette(colors)
    
    plt.rcParams.update({
        'font.size': 11,
        'axes.titlesize': 14,
        'axes.labelsize': 12,
        'xtick.labelsize': 10,
        'ytick.labelsize': 10,
        'legend.fontsize': 11,
        'figure.titlesize': 16,
        'lines.linewidth': 2.5,
        'lines.markersize': 8
    })

def calculate_metrics_from_confusion_matrix(cm):
    """ä»æ··æ·†çŸ©é˜µè®¡ç®—ç²¾ç¡®ç‡ã€å¬å›ç‡å’ŒF1åˆ†æ•°"""
    cm = np.array(cm)
    n_classes = cm.shape[0]
    
    # è®¡ç®—æ¯ä¸ªç±»åˆ«çš„TP, FP, FN
    tp = np.diag(cm)
    fp = np.sum(cm, axis=0) - tp
    fn = np.sum(cm, axis=1) - tp
    
    # é¿å…é™¤é›¶
    precision = np.divide(tp, tp + fp, out=np.zeros_like(tp, dtype=float), where=(tp + fp) != 0)
    recall = np.divide(tp, tp + fn, out=np.zeros_like(tp, dtype=float), where=(tp + fn) != 0)
    
    # è®¡ç®—F1åˆ†æ•°
    f1 = np.divide(2 * precision * recall, precision + recall, 
                   out=np.zeros_like(precision, dtype=float), 
                   where=(precision + recall) != 0)
    
    # è®¡ç®—æ€»ä½“æŒ‡æ ‡ï¼ˆå¾®å¹³å‡ï¼‰
    total_tp = np.sum(tp)
    total_fp = np.sum(fp)
    total_fn = np.sum(fn)
    
    # å¾®å¹³å‡ç²¾ç¡®ç‡ã€å¬å›ç‡å’ŒF1
    micro_precision = total_tp / (total_tp + total_fp) if (total_tp + total_fp) > 0 else 0
    micro_recall = total_tp / (total_tp + total_fn) if (total_tp + total_fn) > 0 else 0
    micro_f1 = 2 * micro_precision * micro_recall / (micro_precision + micro_recall) if (micro_precision + micro_recall) > 0 else 0
    
    return {
        'precision_per_class': precision,
        'recall_per_class': recall,
        'f1_per_class': f1,
        'micro_precision': micro_precision * 100,
        'micro_recall': micro_recall * 100,
        'micro_f1': micro_f1 * 100,
        'macro_precision': np.mean(precision) * 100,
        'macro_recall': np.mean(recall) * 100,
        'macro_f1': np.mean(f1) * 100
    }

def load_macho_1359_data():
    """åŠ è½½MACHO 1359åˆå¹¶çš„è®­ç»ƒæ•°æ®"""
    log_file = "/autodl-fs/data/lnsde-contiformer/results/20250829/MACHO/1359/logs/MACHO_1359_geometric_config1_merged.log"
    
    with open(log_file, 'r') as f:
        data = json.load(f)
    
    training_history = data.get("training_history", {})
    
    epochs = training_history.get("epochs", [])
    train_losses = training_history.get("train_loss", [])
    train_accs = training_history.get("train_accuracy", [])
    val_losses = training_history.get("val_loss", [])
    val_accs = training_history.get("val_accuracy", [])
    train_f1s = training_history.get("train_f1", [])
    train_recalls = training_history.get("train_recall", [])
    val_f1s = training_history.get("val_f1", [])
    val_recalls = training_history.get("val_recall", [])
    learning_rates = training_history.get("learning_rates", [])
    epoch_times = training_history.get("epoch_times", [])
    confusion_matrices = training_history.get("confusion_matrices", [])
    
    return {
        'epochs': epochs,
        'train_loss': train_losses,
        'train_acc': train_accs,
        'val_loss': val_losses,
        'val_acc': val_accs,
        'train_f1': train_f1s,
        'train_recall': train_recalls,
        'val_f1': val_f1s,
        'val_recall': val_recalls,
        'learning_rates': learning_rates,
        'epoch_times': epoch_times,
        'confusion_matrices': confusion_matrices
    }

def create_training_visualization(data, output_path):
    """åˆ›å»º8å­å›¾è®­ç»ƒå¯è§†åŒ–"""
    setup_seaborn_style()
    
    fig, axes = plt.subplots(2, 4, figsize=(20, 12))
    fig.suptitle('MACHO 1359æ•°æ®é›†è®­ç»ƒè¿‡ç¨‹å¯è§†åŒ– (Epochs 21-50)', fontsize=18, y=0.98)
    
    epochs = data['epochs']
    
    # 1. è®­ç»ƒå’ŒéªŒè¯æŸå¤±
    ax = axes[0, 0]
    ax.plot(epochs, data['train_loss'], 'o-', label='è®­ç»ƒæŸå¤±', color='#2E86AB', linewidth=2, markersize=6)
    ax.plot(epochs, data['val_loss'], 's-', label='éªŒè¯æŸå¤±', color='#A23B72', linewidth=2, markersize=6)
    ax.set_title('æŸå¤±å‡½æ•°')
    ax.set_xlabel('Epoch')
    ax.set_ylabel('Loss')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    # æ ‡æ³¨æœ€ä¼˜å€¼
    min_train_loss_idx = np.argmin(data['train_loss'])
    min_val_loss_idx = np.argmin(data['val_loss'])
    ax.annotate(f'æœ€å°è®­ç»ƒæŸå¤±: {data["train_loss"][min_train_loss_idx]:.3f}', 
                xy=(epochs[min_train_loss_idx], data['train_loss'][min_train_loss_idx]), 
                xytext=(10, 10), textcoords='offset points', fontsize=9,
                bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.7))
    
    # 2. è®­ç»ƒå’ŒéªŒè¯å‡†ç¡®ç‡
    ax = axes[0, 1]
    ax.plot(epochs, data['train_acc'], 'o-', label='è®­ç»ƒå‡†ç¡®ç‡', color='#2E86AB', linewidth=2, markersize=6)
    ax.plot(epochs, data['val_acc'], 's-', label='éªŒè¯å‡†ç¡®ç‡', color='#A23B72', linewidth=2, markersize=6)
    ax.set_title('å‡†ç¡®ç‡')
    ax.set_xlabel('Epoch')
    ax.set_ylabel('Accuracy (%)')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    # æ ‡æ³¨æœ€ä¼˜å€¼
    max_train_acc_idx = np.argmax(data['train_acc'])
    max_val_acc_idx = np.argmax(data['val_acc'])
    ax.annotate(f'æœ€é«˜éªŒè¯å‡†ç¡®ç‡: {data["val_acc"][max_val_acc_idx]:.2f}%', 
                xy=(epochs[max_val_acc_idx], data['val_acc'][max_val_acc_idx]), 
                xytext=(10, -20), textcoords='offset points', fontsize=9,
                bbox=dict(boxstyle='round,pad=0.3', facecolor='lightgreen', alpha=0.7))
    
    # 3. F1åˆ†æ•°
    ax = axes[0, 2]
    ax.plot(epochs, data['train_f1'], 'o-', label='è®­ç»ƒF1', color='#F18F01', linewidth=2, markersize=6)
    ax.plot(epochs, data['val_f1'], 's-', label='éªŒè¯F1', color='#C73E1D', linewidth=2, markersize=6)
    ax.set_title('F1åˆ†æ•°')
    ax.set_xlabel('Epoch')
    ax.set_ylabel('F1 Score')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    # 4. å¬å›ç‡
    ax = axes[0, 3]
    ax.plot(epochs, data['train_recall'], 'o-', label='è®­ç»ƒå¬å›ç‡', color='#7209B7', linewidth=2, markersize=6)
    ax.plot(epochs, data['val_recall'], 's-', label='éªŒè¯å¬å›ç‡', color='#2E86AB', linewidth=2, markersize=6)
    ax.set_title('å¬å›ç‡')
    ax.set_xlabel('Epoch')
    ax.set_ylabel('Recall')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    # 5. å­¦ä¹ ç‡å˜åŒ–
    ax = axes[1, 0]
    ax.plot(epochs, data['learning_rates'], 'o-', color='#A23B72', linewidth=2, markersize=6)
    ax.set_title('å­¦ä¹ ç‡å˜åŒ–')
    ax.set_xlabel('Epoch')
    ax.set_ylabel('Learning Rate')
    ax.set_yscale('log')
    ax.grid(True, alpha=0.3)
    
    # 6. Epochè®­ç»ƒæ—¶é—´
    ax = axes[1, 1]
    epoch_times_min = [t/60 for t in data['epoch_times']]  # è½¬æ¢ä¸ºåˆ†é’Ÿ
    ax.plot(epochs, epoch_times_min, 'o-', color='#F18F01', linewidth=2, markersize=6)
    ax.set_title('æ¯ä¸ªEpochè®­ç»ƒæ—¶é—´')
    ax.set_xlabel('Epoch')
    ax.set_ylabel('æ—¶é—´ (åˆ†é’Ÿ)')
    ax.grid(True, alpha=0.3)
    
    # 7. è®­ç»ƒè¿›åº¦æ€»è§ˆ
    ax = axes[1, 2]
    # å½’ä¸€åŒ–å„æŒ‡æ ‡åˆ°0-100èŒƒå›´è¿›è¡Œæ¯”è¾ƒ
    norm_train_acc = np.array(data['train_acc'])
    norm_val_acc = np.array(data['val_acc'])
    norm_train_f1 = np.array(data['train_f1'])
    norm_val_f1 = np.array(data['val_f1'])
    
    ax.plot(epochs, norm_train_acc, '--', label='è®­ç»ƒå‡†ç¡®ç‡', alpha=0.7)
    ax.plot(epochs, norm_val_acc, '--', label='éªŒè¯å‡†ç¡®ç‡', alpha=0.7)
    ax.plot(epochs, norm_train_f1, '-', label='è®­ç»ƒF1')
    ax.plot(epochs, norm_val_f1, '-', label='éªŒè¯F1')
    ax.set_title('ç»¼åˆæŒ‡æ ‡å¯¹æ¯”')
    ax.set_xlabel('Epoch')
    ax.set_ylabel('æŒ‡æ ‡å€¼')
    ax.legend(fontsize=9)
    ax.grid(True, alpha=0.3)
    
    # 8. æœ€ç»ˆæ··æ·†çŸ©é˜µçƒ­å›¾
    ax = axes[1, 3]
    if data['confusion_matrices']:
        final_cm = np.array(data['confusion_matrices'][-1])
        im = ax.imshow(final_cm, interpolation='nearest', cmap='Blues')
        ax.set_title(f'æœ€ç»ˆæ··æ·†çŸ©é˜µ (Epoch {epochs[-1]})')
        
        # æ·»åŠ æ•°å€¼æ ‡æ³¨
        for i in range(final_cm.shape[0]):
            for j in range(final_cm.shape[1]):
                ax.text(j, i, str(final_cm[i, j]), 
                       ha="center", va="center", color="black" if final_cm[i, j] < final_cm.max()/2 else "white")
        
        ax.set_xlabel('é¢„æµ‹ç±»åˆ«')
        ax.set_ylabel('çœŸå®ç±»åˆ«')
        
        # æ·»åŠ colorbar
        cbar = plt.colorbar(im, ax=ax, shrink=0.8)
        cbar.set_label('æ ·æœ¬æ•°é‡', rotation=270, labelpad=20)
    
    plt.tight_layout()
    plt.subplots_adjust(top=0.93)
    
    # ä¿å­˜å›¾ç‰‡
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"è®­ç»ƒå¯è§†åŒ–å·²ä¿å­˜åˆ°: {output_path}")
    
    # è®¡ç®—å¹¶è¿”å›æœ€ä¼˜å€¼
    best_values = {
        'train_acc': {'value': max(data['train_acc']), 'epoch': epochs[np.argmax(data['train_acc'])]},
        'val_acc': {'value': max(data['val_acc']), 'epoch': epochs[np.argmax(data['val_acc'])]},
        'train_loss': {'value': min(data['train_loss']), 'epoch': epochs[np.argmin(data['train_loss'])]},
        'val_loss': {'value': min(data['val_loss']), 'epoch': epochs[np.argmin(data['val_loss'])]},
        'train_f1': {'value': max(data['train_f1']), 'epoch': epochs[np.argmax(data['train_f1'])]},
        'val_f1': {'value': max(data['val_f1']), 'epoch': epochs[np.argmax(data['val_f1'])]},
        'train_recall': {'value': max(data['train_recall']), 'epoch': epochs[np.argmax(data['train_recall'])]},
        'val_recall': {'value': max(data['val_recall']), 'epoch': epochs[np.argmax(data['val_recall'])]}
    }
    
    return best_values

def main():
    """ä¸»å‡½æ•°"""
    print("å¼€å§‹ç”ŸæˆMACHO 1359æ•°æ®é›†è®­ç»ƒå¯è§†åŒ–...")
    
    # åŠ è½½æ•°æ®
    data = load_macho_1359_data()
    print(f"æˆåŠŸåŠ è½½æ•°æ®ï¼ŒåŒ…å«epochs: {min(data['epochs'])} - {max(data['epochs'])}")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = "/autodl-fs/data/lnsde-contiformer/results/pics/MACHO/"
    os.makedirs(output_dir, exist_ok=True)
    
    # ç”Ÿæˆå¯è§†åŒ–
    output_path = os.path.join(output_dir, "macho_1359_training_epochs21-50.png")
    best_values = create_training_visualization(data, output_path)
    
    # è¾“å‡ºæœ€ä¼˜å€¼æ€»ç»“
    print(f"\n=== MACHO 1359 è®­ç»ƒæœ€ä¼˜å€¼æ€»ç»“ (Epochs 21-50) ===")
    print(f"ğŸ† æœ€é«˜è®­ç»ƒå‡†ç¡®ç‡: {best_values['train_acc']['value']:.2f}% (Epoch {best_values['train_acc']['epoch']})")
    print(f"ğŸ† æœ€é«˜éªŒè¯å‡†ç¡®ç‡: {best_values['val_acc']['value']:.2f}% (Epoch {best_values['val_acc']['epoch']})")
    print(f"ğŸ“‰ æœ€ä½è®­ç»ƒæŸå¤±: {best_values['train_loss']['value']:.4f} (Epoch {best_values['train_loss']['epoch']})")
    print(f"ğŸ“‰ æœ€ä½éªŒè¯æŸå¤±: {best_values['val_loss']['value']:.4f} (Epoch {best_values['val_loss']['epoch']})")
    print(f"ğŸ¯ æœ€é«˜è®­ç»ƒF1: {best_values['train_f1']['value']:.2f} (Epoch {best_values['train_f1']['epoch']})")
    print(f"ğŸ¯ æœ€é«˜éªŒè¯F1: {best_values['val_f1']['value']:.2f} (Epoch {best_values['val_f1']['epoch']})")
    print(f"ğŸ“Š æœ€é«˜è®­ç»ƒå¬å›ç‡: {best_values['train_recall']['value']:.2f} (Epoch {best_values['train_recall']['epoch']})")
    print(f"ğŸ“Š æœ€é«˜éªŒè¯å¬å›ç‡: {best_values['val_recall']['value']:.2f} (Epoch {best_values['val_recall']['epoch']})")
    
    print(f"\nâœ… MACHO 1359 è®­ç»ƒå¯è§†åŒ–å®Œæˆï¼Œå›¾ç‰‡ä¿å­˜è‡³: {output_path}")

if __name__ == "__main__":
    main()