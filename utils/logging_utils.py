"""
æ—¥å¿—ç›¸å…³å·¥å…·å‡½æ•°
"""

import os
import json
import time
from datetime import datetime
from .path_manager import get_log_path


def setup_logging(timestamp_dir, dataset_name, model_type, sde_config, args=None):
    """è®¾ç½®æ—¥å¿—è®°å½• - ä½¿ç”¨æ–°çš„æ—¶é—´æˆ³ç›®å½•ç»“æ„"""
    now = datetime.now()
    timestamp = now.strftime("%Y%m%d_%H%M%S")
    date_str = now.strftime("%Y%m%d")
    
    # æ„å»ºåŒ…å«æ¨¡å‹å‚æ•°çš„æ—¥å¿—æ–‡ä»¶å
    if args is not None:
        # åŸºç¡€æ¨¡å‹ç±»å‹æ˜ å°„
        base_model_map = {1: 'langevin', 2: 'linear_noise', 3: 'geometric'}
        base_model = base_model_map.get(model_type, f'model{model_type}')
        
        # ç»„ä»¶å¼€å…³çŠ¶æ€
        use_sde = getattr(args, 'use_sde', 1)
        use_contiformer = getattr(args, 'use_contiformer', 1)
        
        # æ ¹æ®ç»„ä»¶å¼€å…³ç»„åˆç¡®å®šå®Œæ•´æ¨¡å‹ç±»å‹
        if use_sde and use_contiformer:
            model_name = f"{base_model}_sde_cf"  # å®Œæ•´æ¨¡å‹
        elif use_sde and not use_contiformer:
            model_name = f"{base_model}_sde_only"  # åªæœ‰SDE
        elif not use_sde and use_contiformer:
            model_name = "contiformer_only"   # åªæœ‰ContiFormerï¼Œä¸éœ€è¦SDEç±»å‹
        else:
            model_name = "baseline"  # åŸºç¡€æ¨¡å‹ï¼Œä¸éœ€è¦SDEç±»å‹
        
        # å…³é”®å‚æ•°ä¿¡æ¯
        lr = getattr(args, 'learning_rate', 1e-4)
        batch_size = getattr(args, 'batch_size', 64)
        hidden_channels = getattr(args, 'hidden_channels', 128)
        contiformer_dim = getattr(args, 'contiformer_dim', 128)
        
        # æ„å»ºè¯¦ç»†æ–‡ä»¶å
        filename = (f"{dataset_name}_{model_name}_config{sde_config}"
                   f"_lr{lr:.0e}_bs{batch_size}_hc{hidden_channels}_cd{contiformer_dim}.log")
    else:
        # ä¿æŒåŸæœ‰æ ¼å¼ä½œä¸ºåå¤‡
        filename = f"{dataset_name}_{model_type}_config{sde_config}.log"
    
    # ä½¿ç”¨æ–°çš„è·¯å¾„ç®¡ç†è·å–æ—¥å¿—è·¯å¾„
    log_path = os.path.join(timestamp_dir, "logs", filename)
    
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    os.makedirs(os.path.dirname(log_path), exist_ok=True)
    
    # åˆå§‹åŒ–æ—¥å¿—æ•°æ®
    log_data = {
        'dataset': dataset_name,
        'model_type': model_type,
        'sde_config': sde_config,
        'start_time': timestamp,
        'date': date_str,
        'best_epoch': 0,  # å½“å‰æœ€ä½³epoch
        'best_val_acc': 0.0,  # å½“å‰æœ€ä½³éªŒè¯å‡†ç¡®ç‡
        'best_timestamp': None,  # æœ€ä½³å‡†ç¡®ç‡è¾¾æˆæ—¶é—´
        'epochs': []
    }
    
    print(f"æ—¥å¿—æ–‡ä»¶: {log_path}")
    return log_path, log_data


def update_log(log_path, log_data, epoch, train_loss, train_acc, val_loss, val_acc, 
               class_accuracies=None, total_time=None, lr=None, train_metrics=None, val_metrics=None, 
               is_best=False):
    """æ›´æ–°æ—¥å¿—æ•°æ®"""
    epoch_data = {
        'epoch': epoch,
        'train_loss': float(train_loss),
        'train_acc': float(train_acc),
        'val_loss': float(val_loss),
        'val_acc': float(val_acc),
        'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        'is_best': is_best  # æ ‡è®°æ˜¯å¦ä¸ºæœ€ä½³epoch
    }
    
    # æ·»åŠ è®­ç»ƒé¢å¤–æŒ‡æ ‡ (å®å¹³å‡)
    if train_metrics is not None:
        epoch_data['train_f1'] = float(train_metrics['f1_score'])  # å®å¹³å‡F1
        epoch_data['train_recall'] = float(train_metrics['recall'])  # å®å¹³å‡Recall

    # æ·»åŠ éªŒè¯é¢å¤–æŒ‡æ ‡ (å®å¹³å‡)
    if val_metrics is not None:
        epoch_data['val_f1'] = float(val_metrics['f1_score'])  # å®å¹³å‡F1
        epoch_data['val_recall'] = float(val_metrics['recall'])  # å®å¹³å‡Recall
        
        # æ¯ä¸ªepochéƒ½ä¿å­˜æ··æ·†çŸ©é˜µï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if 'confusion_matrix' in val_metrics and val_metrics['confusion_matrix'] is not None:
            cm = val_metrics['confusion_matrix']
            # å¯¹äºnumpyæ•°ç»„ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰å…ƒç´ ä¸”ä¸å…¨ä¸º0
            if hasattr(cm, 'size') and cm.size > 0:
                epoch_data['confusion_matrix'] = cm.tolist()  # è½¬ä¸ºåˆ—è¡¨ä¾¿äºJSONåºåˆ—åŒ–
    
    # æ¯ä¸ªepochéƒ½è®°å½•class_accuraciesï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    if class_accuracies is not None:
        epoch_data['class_accuracies'] = {k: float(v) for k, v in class_accuracies.items()}
    
    if total_time is not None:
        epoch_data['epoch_time'] = float(total_time)
        
    if lr is not None:
        epoch_data['learning_rate'] = float(lr)
    
    # æ›´æ–°æœ€ä½³epochè®°å½•
    if is_best:
        log_data['best_epoch'] = epoch
        log_data['best_val_acc'] = float(val_acc)
        log_data['best_timestamp'] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    log_data['epochs'].append(epoch_data)
    
    # ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
    os.makedirs(os.path.dirname(log_path), exist_ok=True)
    
    # ä¿å­˜æ—¥å¿—æ–‡ä»¶
    with open(log_path, 'w', encoding='utf-8') as f:
        json.dump(log_data, f, ensure_ascii=False, indent=2)


def print_epoch_summary(epoch, total_epochs, train_loss, train_acc, val_loss, val_acc, 
                       class_accuracies=None, epoch_time=None, lr=None, train_metrics=None, val_metrics=None, best_epoch=None):
    """æ‰“å°è®­ç»ƒè½®æ¬¡æ€»ç»“"""
    print(f"\nEpoch [{epoch}/{total_epochs}] æ€»ç»“:")
    
    # è®­ç»ƒæŒ‡æ ‡
    train_info = f"  è®­ç»ƒ - Loss: {train_loss:.4f}, Acc: {train_acc:.2f}%"
    if train_metrics:
        train_info += f", å®F1: {train_metrics['f1_score']*100:.1f}%, å®Recall: {train_metrics['recall']*100:.1f}%"
    print(train_info)

    # éªŒè¯æŒ‡æ ‡
    val_info = f"  éªŒè¯ - Loss: {val_loss:.4f}, Acc: {val_acc:.2f}%"
    if val_metrics:
        val_info += f", å®F1: {val_metrics['f1_score']*100:.1f}%, å®Recall: {val_metrics['recall']*100:.1f}%"
    print(val_info)
    
    # æ˜¾ç¤ºæœ€ä½³epochä¿¡æ¯
    if best_epoch is not None and best_epoch > 0:
        if epoch == best_epoch:
            print(f"  ğŸ‰ æ–°çš„æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {val_acc:.2f}% (Epoch {best_epoch})")
        else:
            print(f"  ğŸ“Š å½“å‰æœ€ä½³: Epoch {best_epoch}")
    
    if lr is not None:
        print(f"  å­¦ä¹ ç‡: {lr:.2e}")
    
    if epoch_time is not None:
        print(f"  è€—æ—¶: {epoch_time:.1f}s")
    
    if val_metrics and 'confusion_matrix' in val_metrics and val_metrics['confusion_matrix'] is not None:
        confusion_matrix = val_metrics['confusion_matrix']
        # ç¡®ä¿æ˜¯æœ‰æ•ˆçš„çŸ©é˜µ
        if hasattr(confusion_matrix, 'shape') and confusion_matrix.size > 0:
            print("  æ··æ·†çŸ©é˜µ:")
            num_classes = confusion_matrix.shape[0]
            
            # ç›´æ¥æ‰“å°n*nçŸ©é˜µï¼Œæ¯è¡Œç¼©è¿›4ä¸ªç©ºæ ¼
            for i in range(num_classes):
                print("    ", end="")
                for j in range(num_classes):
                    print(f"{confusion_matrix[i, j]:>4}", end=" ")
                print()
    elif class_accuracies is not None:
        # å¤‡ç”¨æ˜¾ç¤ºï¼šå¦‚æœæ²¡æœ‰æ··æ·†çŸ©é˜µï¼Œä»æ˜¾ç¤ºå„ç±»åˆ«å‡†ç¡®ç‡
        print("  å„ç±»åˆ«å‡†ç¡®ç‡:")
        for class_name, acc in class_accuracies.items():
            print(f"    {class_name}: {acc:.2f}%")
    
    print("-" * 80)