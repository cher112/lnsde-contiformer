#!/usr/bin/env python3
"""
NaNæ ·æœ¬åˆ†æžå’Œç»Ÿè®¡å·¥å…·
"""

import os
import re
from collections import defaultdict, Counter


def analyze_nan_log():
    """åˆ†æžnan_samples.logæ–‡ä»¶ï¼Œç”Ÿæˆè¯¦ç»†ç»Ÿè®¡"""
    
    log_file = 'nan_samples.log'
    if not os.path.exists(log_file):
        print("æ²¡æœ‰æ‰¾åˆ°nan_samples.logæ–‡ä»¶")
        return
    
    print("="*70)
    print("NaNæ ·æœ¬è¿‡æ»¤ç»Ÿè®¡åˆ†æž")
    print("="*70)
    
    # ç»Ÿè®¡æ•°æ®ç»“æž„
    epoch_stats = defaultdict(lambda: {'total': 0, 'batches': set(), 'samples': []})
    batch_stats = defaultdict(lambda: {'epoch': 0, 'samples': []})
    sample_frequency = Counter()
    total_filtered = 0
    
    # è§£æžæ—¥å¿—æ–‡ä»¶
    with open(log_file, 'r') as f:
        for line in f:
            line = line.strip()
            if not line or 'filtered out' not in line:
                continue
            
            # è§£æž: "Epoch 5, Batch 123, Sample 7 filtered out (NaN loss)"
            match = re.search(r'Epoch (\d+), Batch (\d+), Sample (\d+)', line)
            if match:
                epoch = int(match.group(1))
                batch = int(match.group(2))
                sample = int(match.group(3))
                
                # æ›´æ–°ç»Ÿè®¡
                epoch_stats[epoch]['total'] += 1
                epoch_stats[epoch]['batches'].add(batch)
                epoch_stats[epoch]['samples'].append(sample)
                
                batch_stats[f"{epoch}_{batch}"]['epoch'] = epoch
                batch_stats[f"{epoch}_{batch}"]['samples'].append(sample)
                
                sample_frequency[f"E{epoch}_B{batch}_S{sample}"] += 1
                total_filtered += 1
    
    # æ˜¾ç¤ºç»Ÿè®¡ç»“æžœ
    print(f"\nðŸ“Š æ€»ä½“ç»Ÿè®¡:")
    print(f"  æ€»è¿‡æ»¤æ ·æœ¬æ•°: {total_filtered}")
    print(f"  æ¶‰åŠè½®æ¬¡æ•°: {len(epoch_stats)}")
    print(f"  æ¶‰åŠæ‰¹æ¬¡æ•°: {len(batch_stats)}")
    
    if len(epoch_stats) > 0:
        print(f"\nðŸ“ˆ æŒ‰è½®æ¬¡ç»Ÿè®¡:")
        for epoch in sorted(epoch_stats.keys()):
            stats = epoch_stats[epoch]
            print(f"  Epoch {epoch}: {stats['total']} ä¸ªæ ·æœ¬, {len(stats['batches'])} ä¸ªæ‰¹æ¬¡")
        
        print(f"\nðŸŽ¯ æœ€é¢‘ç¹å‡ºçŽ°NaNçš„æ‰¹æ¬¡:")
        batch_sample_counts = {}
        for key, stats in batch_stats.items():
            epoch, batch = key.split('_')
            batch_sample_counts[key] = len(stats['samples'])
        
        top_batches = sorted(batch_sample_counts.items(), key=lambda x: x[1], reverse=True)[:10]
        for batch_key, sample_count in top_batches:
            epoch, batch = batch_key.split('_')
            print(f"  Epoch {epoch}, Batch {batch}: {sample_count} ä¸ªæ ·æœ¬")
        
        # åˆ†æžæ ·æœ¬åœ¨æ‰¹æ¬¡ä¸­çš„ä½ç½®åˆ†å¸ƒ
        print(f"\nðŸ“ æ ·æœ¬ä½ç½®åˆ†å¸ƒåˆ†æž:")
        all_sample_positions = []
        for stats in epoch_stats.values():
            all_sample_positions.extend(stats['samples'])
        
        if all_sample_positions:
            position_counter = Counter(all_sample_positions)
            print(f"  æœ€å¸¸å‡ºçŽ°NaNçš„æ ·æœ¬ä½ç½®:")
            top_positions = position_counter.most_common(10)
            for pos, count in top_positions:
                print(f"    ä½ç½® {pos}: {count} æ¬¡")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰é‡å¤å‡ºçŽ°çš„æ ·æœ¬
        print(f"\nðŸ”„ é‡å¤å‡ºçŽ°çš„æ ·æœ¬:")
        repeated = [(k, v) for k, v in sample_frequency.items() if v > 1]
        if repeated:
            repeated.sort(key=lambda x: x[1], reverse=True)
            for sample, count in repeated[:10]:
                print(f"  {sample}: {count} æ¬¡")
        else:
            print("  æ²¡æœ‰æ ·æœ¬å¤šæ¬¡å‡ºçŽ°NaN")
    
    print(f"\nðŸ’¡ å»ºè®®:")
    if total_filtered > 0:
        filter_rate = total_filtered / max(len(batch_stats) * 20, 1) * 100  # å‡è®¾æ¯æ‰¹æ¬¡20ä¸ªæ ·æœ¬
        print(f"  æ ·æœ¬è¿‡æ»¤çŽ‡çº¦: {filter_rate:.2f}%")
        
        if filter_rate > 5:
            print("  âš ï¸  è¿‡æ»¤çŽ‡è¾ƒé«˜ï¼Œå»ºè®®æ£€æŸ¥:")
            print("    - æ¨¡åž‹å‚æ•°æ˜¯å¦åˆé€‚")
            print("    - å­¦ä¹ çŽ‡æ˜¯å¦è¿‡å¤§")
            print("    - æ•°æ®é¢„å¤„ç†æ˜¯å¦æ­£ç¡®")
        elif filter_rate > 1:
            print("  âœ… è¿‡æ»¤çŽ‡é€‚ä¸­ï¼Œæ¨¡åž‹è®­ç»ƒåŸºæœ¬ç¨³å®š")
        else:
            print("  ðŸŽ‰ è¿‡æ»¤çŽ‡å¾ˆä½Žï¼Œæ¨¡åž‹è®­ç»ƒéžå¸¸ç¨³å®š")
    
    print("="*70)


def clean_nan_log():
    """æ¸…ç†è¿‡æ—§çš„æ—¥å¿—æ–‡ä»¶"""
    log_file = 'nan_samples.log'
    if os.path.exists(log_file):
        # å¤‡ä»½æ—§æ—¥å¿—
        backup_file = f"{log_file}.backup"
        if os.path.exists(backup_file):
            os.remove(backup_file)
        os.rename(log_file, backup_file)
        print(f"å·²å¤‡ä»½æ—§æ—¥å¿—åˆ°: {backup_file}")
        print("æ–°çš„è®­ç»ƒå°†åˆ›å»ºæ–°çš„æ—¥å¿—æ–‡ä»¶")
    else:
        print("æ²¡æœ‰æ‰¾åˆ°éœ€è¦æ¸…ç†çš„æ—¥å¿—æ–‡ä»¶")


if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == 'clean':
        clean_nan_log()
    else:
        analyze_nan_log()