#!/usr/bin/env python3
"""
æµ‹è¯•ç‰©ç†çº¦æŸTimeGANæ•°æ®æ˜¯å¦å¯ä»¥æ­£å¸¸ç”¨äºmain.pyè®­ç»ƒ
å¿«é€ŸéªŒè¯æ•°æ®æ ¼å¼å…¼å®¹æ€§å’Œè®­ç»ƒæµç¨‹
"""

import sys
import os
import torch
import argparse

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append('/root/autodl-tmp/lnsde-contiformer')

from utils import create_dataloaders, setup_dataset_mapping, get_dataset_specific_params

def test_timegan_data_loading():
    """æµ‹è¯•TimeGANæ•°æ®åŠ è½½"""
    print("ğŸ”§ æµ‹è¯•ç‰©ç†çº¦æŸTimeGANæ•°æ®åŠ è½½...")
    
    # æ¨¡æ‹Ÿå‘½ä»¤è¡Œå‚æ•°
    args = argparse.Namespace()
    args.dataset = 3  # MACHO
    args.model_type = 2  # æ·»åŠ æ¨¡å‹ç±»å‹å‚æ•°
    args.use_resampling = True  # ä½¿ç”¨é‡é‡‡æ ·æ•°æ®
    args.resampled_data_path = None  # ä½¿ç”¨é»˜è®¤TimeGANè·¯å¾„
    args.batch_size = 32
    args.temperature = None
    args.focal_gamma = None
    args.min_time_interval = None
    
    # è®¾ç½®æ•°æ®é›†æ˜ å°„
    args = setup_dataset_mapping(args)
    
    print(f"æ•°æ®è·¯å¾„: {args.data_path}")
    print(f"æ•°æ®é›†åç§°: {args.dataset_name}")
    
    # è·å–æ•°æ®é›†ç‰¹å®šé…ç½®
    config = get_dataset_specific_params(args.dataset, args)
    
    # æµ‹è¯•æ•°æ®åŠ è½½å™¨åˆ›å»º
    try:
        train_loader, test_loader, num_classes = create_dataloaders(
            data_path=args.data_path,
            batch_size=args.batch_size,
            train_ratio=0.7,  # ä¿®æ­£å‚æ•°å
            test_ratio=0.3,   # ä¿®æ­£å‚æ•°å 
            normalize=False,  # ä¸å½’ä¸€åŒ–
            num_workers=0,  # å•çº¿ç¨‹é¿å…é—®é¢˜
            random_seed=42
        )
        
        print(f"âœ… æ•°æ®åŠ è½½å™¨åˆ›å»ºæˆåŠŸ!")
        print(f"   è®­ç»ƒé›†: {len(train_loader)} æ‰¹æ¬¡")
        print(f"   æµ‹è¯•é›†: {len(test_loader)} æ‰¹æ¬¡")
        print(f"   ç±»åˆ«æ•°: {num_classes}")
        
        # æµ‹è¯•æ•°æ®æ‰¹æ¬¡
        print(f"\nğŸ” æ£€æŸ¥æ•°æ®æ‰¹æ¬¡...")
        for batch_idx, batch in enumerate(train_loader):
            if batch_idx >= 2:  # åªæ£€æŸ¥å‰2ä¸ªæ‰¹æ¬¡
                break
            
            print(f"æ‰¹æ¬¡ {batch_idx + 1}: {len(batch)} ä¸ªå…ƒç´ ")
            for i, item in enumerate(batch):
                if hasattr(item, 'shape'):
                    print(f"  å…ƒç´  {i}: {item.shape} {item.dtype}")
                else:
                    print(f"  å…ƒç´  {i}: {type(item)} {item}")
            
            # æ ¹æ®å®é™…æ ¼å¼è§£åŒ…
            if len(batch) == 7:  # 7ä¸ªå…ƒç´ çš„æƒ…å†µ
                times, mags, errmags, masks, periods, labels, other = batch
            elif len(batch) == 6:
                times, mags, errmags, masks, periods, labels = batch
            else:
                print(f"  æœªçŸ¥çš„batchæ ¼å¼ï¼Œè·³è¿‡è¯¦ç»†æ£€æŸ¥")
                continue
            
            print(f"æ‰¹æ¬¡ {batch_idx + 1}:")
            print(f"  times: {times.shape} {times.dtype}")
            print(f"  mags: {mags.shape} {mags.dtype}")
            print(f"  errmags: {errmags.shape} {errmags.dtype}")
            print(f"  masks: {masks.shape} {masks.dtype}")
            print(f"  periods: {periods.shape} {periods.dtype}")
            print(f"  labels: {labels.shape} {labels.dtype}")
            print(f"  æ ‡ç­¾åˆ†å¸ƒ: {torch.bincount(labels)}")
            
            # æ£€æŸ¥æ•°æ®å€¼èŒƒå›´
            print(f"  æ•°æ®èŒƒå›´æ£€æŸ¥:")
            print(f"    æ—¶é—´: [{times.min():.3f}, {times.max():.3f}]")
            print(f"    æ˜Ÿç­‰: [{mags.min():.3f}, {mags.max():.3f}]")
            print(f"    è¯¯å·®: [{errmags.min():.3f}, {errmags.max():.3f}]")
            print(f"    æœ‰æ•ˆæ©ç æ¯”ä¾‹: {masks.float().mean():.3f}")
            
            # æ£€æŸ¥NaNå€¼
            has_nan = False
            for tensor_name, tensor in [('times', times), ('mags', mags), ('errmags', errmags)]:
                if torch.isnan(tensor).any():
                    print(f"    âš ï¸ {tensor_name}åŒ…å«NaNå€¼!")
                    has_nan = True
            
            if not has_nan:
                print(f"    âœ… æ•°æ®ä¸­æ— NaNå€¼")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

def test_with_different_paths():
    """æµ‹è¯•ä¸åŒçš„æ•°æ®è·¯å¾„é€‰é¡¹"""
    print(f"\nğŸ” æµ‹è¯•ä¸åŒæ•°æ®è·¯å¾„é€‰é¡¹...")
    
    test_configs = [
        {
            'name': 'é»˜è®¤TimeGANé‡é‡‡æ ·',
            'use_resampling': True,
            'resampled_data_path': None
        },
        {
            'name': 'æŒ‡å®šTimeGANè·¯å¾„',
            'use_resampling': True, 
            'resampled_data_path': '/root/autodl-fs/lnsde-contiformer/data/macho_resample_timegan.pkl'
        },
        {
            'name': 'åŸå§‹æ•°æ®å¯¹æ¯”',
            'use_original': True
        }
    ]
    
    for config in test_configs:
        print(f"\nğŸ“Š æµ‹è¯•é…ç½®: {config['name']}")
        
        # åˆ›å»ºå‚æ•°
        args = argparse.Namespace()
        args.dataset = 3
        args.model_type = 2  # æ·»åŠ æ¨¡å‹ç±»å‹å‚æ•°
        for key, value in config.items():
            if key != 'name':
                setattr(args, key, value)
        
        # è®¾ç½®æ•°æ®é›†æ˜ å°„
        try:
            args = setup_dataset_mapping(args)
            print(f"  âœ… æ•°æ®è·¯å¾„: {args.data_path}")
            print(f"  âœ… æ•°æ®é›†åç§°: {args.dataset_name}")
        except Exception as e:
            print(f"  âŒ é…ç½®å¤±è´¥: {str(e)}")

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ ç‰©ç†çº¦æŸTimeGANæ•°æ®å…¼å®¹æ€§æµ‹è¯•")
    print("=" * 50)
    
    # 1. æµ‹è¯•æ•°æ®åŠ è½½
    success = test_timegan_data_loading()
    
    if success:
        print(f"\nâœ… TimeGANæ•°æ®å®Œå…¨å…¼å®¹main.pyï¼")
        
        # 2. æµ‹è¯•ä¸åŒè·¯å¾„é…ç½®
        test_with_different_paths()
        
        # 3. æä¾›ä½¿ç”¨è¯´æ˜
        print(f"\nğŸ¯ main.pyä½¿ç”¨è¯´æ˜:")
        print(f"# ä½¿ç”¨ç‰©ç†çº¦æŸTimeGANé‡é‡‡æ ·æ•°æ®è®­ç»ƒ:")
        print(f"python main.py --dataset 3 --use_resampling")
        print(f"")
        print(f"# æˆ–æŒ‡å®šå…·ä½“è·¯å¾„:")
        print(f"python main.py --dataset 3 --use_resampling --resampled_data_path /root/autodl-fs/lnsde-contiformer/data/macho_resample_timegan.pkl")
        print(f"")
        print(f"# æ¨èè®­ç»ƒé…ç½®ï¼ˆå……åˆ†åˆ©ç”¨TimeGANæ•°æ®ä¼˜åŠ¿ï¼‰:")
        print(f"python main.py --dataset 3 --use_resampling --epochs 100 --batch_size 64 --learning_rate 1e-4")
        
    else:
        print(f"\nâŒ TimeGANæ•°æ®å…¼å®¹æ€§æµ‹è¯•å¤±è´¥")
        print(f"è¯·æ£€æŸ¥æ•°æ®æ ¼å¼æˆ–è”ç³»å¼€å‘è€…")
    
    return success

if __name__ == "__main__":
    success = main()
    if success:
        print(f"\nğŸ‰ æµ‹è¯•æˆåŠŸï¼å¯ä»¥å¼€å§‹ä½¿ç”¨ç‰©ç†çº¦æŸTimeGANæ•°æ®è¿›è¡Œè®­ç»ƒäº†ï¼")
    else:
        print(f"\nâš ï¸ æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦ä¿®å¤é—®é¢˜åå†è¯•")