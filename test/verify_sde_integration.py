#!/usr/bin/env python3
"""
éªŒè¯æ‰€æœ‰SDEæ¨¡å‹é›†æˆæµ‹è¯•
æµ‹è¯•Langevin, LinearNoise, Geometricä¸‰ç§SDEä¸ContiFormer + CGAçš„é›†æˆ
"""

import torch
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, '/root/autodl-tmp/lnsde-contiformer')

from models import (
    LangevinSDEContiformer,
    LinearNoiseSDEContiformer, 
    GeometricSDEContiformer
)

def test_model_integration():
    """æµ‹è¯•æ‰€æœ‰æ¨¡å‹çš„é›†æˆåŠŸèƒ½"""
    print("=== SDEæ¨¡å‹é›†æˆæµ‹è¯• ===")
    
    # æµ‹è¯•æ•°æ®
    batch_size = 4
    seq_len = 100
    input_dim = 3
    num_classes = 7
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    time_series = torch.randn(batch_size, seq_len, input_dim)
    time_series[:, :, 0] = torch.sort(torch.rand(batch_size, seq_len), dim=1)[0]  # ç¡®ä¿æ—¶é—´é€’å¢
    
    # åˆ›å»ºmask (æ¨¡æ‹Ÿä¸è§„åˆ™æ—¶é—´åºåˆ—)
    mask = torch.ones(batch_size, seq_len, dtype=torch.bool)
    for i in range(batch_size):
        # éšæœºè®¾ç½®ä¸€äº›ä½ç½®ä¸ºFalse
        invalid_positions = torch.randperm(seq_len)[:seq_len//4]
        mask[i, invalid_positions] = False
    
    print(f"æµ‹è¯•æ•°æ®å½¢çŠ¶: {time_series.shape}")
    print(f"Maskå½¢çŠ¶: {mask.shape}")
    print(f"æœ‰æ•ˆæ•°æ®æ¯”ä¾‹: {mask.float().mean():.2f}")
    
    # æµ‹è¯•é…ç½®
    model_configs = {
        'basic': {
            'use_sde': True,
            'use_contiformer': True,  
            'use_cga': False
        },
        'with_cga': {
            'use_sde': True,
            'use_contiformer': True,
            'use_cga': True
        },
        'no_sde': {
            'use_sde': False,
            'use_contiformer': True,
            'use_cga': False
        },
        'no_contiformer': {
            'use_sde': True,
            'use_contiformer': False,
            'use_cga': False
        },
        'minimal': {
            'use_sde': False,
            'use_contiformer': False,
            'use_cga': False
        }
    }
    
    # æµ‹è¯•æ‰€æœ‰æ¨¡å‹ç±»å‹
    model_classes = {
        'Langevin': LangevinSDEContiformer,
        'LinearNoise': LinearNoiseSDEContiformer,
        'Geometric': GeometricSDEContiformer
    }
    
    results = {}
    
    for model_name, ModelClass in model_classes.items():
        print(f"\n--- æµ‹è¯• {model_name} SDE ---")
        results[model_name] = {}
        
        for config_name, config in model_configs.items():
            print(f"  é…ç½®: {config_name} {config}")
            
            try:
                # åˆ›å»ºæ¨¡å‹
                model = ModelClass(
                    input_dim=input_dim,
                    num_classes=num_classes,
                    hidden_channels=32,  # å°ä¸€ç‚¹å‡å°‘è®¡ç®—é‡
                    contiformer_dim=64,
                    n_heads=4,
                    n_layers=2,
                    dropout=0.1,
                    dt=0.1,  # å¤§æ­¥é•¿å¿«é€Ÿæµ‹è¯•
                    rtol=1e-3,
                    atol=1e-4,
                    **config
                )
                
                model.eval()
                
                # å‰å‘ä¼ æ’­æµ‹è¯•
                with torch.no_grad():
                    logits = model(time_series, mask)
                
                # éªŒè¯è¾“å‡º
                assert logits.shape == (batch_size, num_classes), f"è¾“å‡ºå½¢çŠ¶é”™è¯¯: {logits.shape}"
                assert not torch.isnan(logits).any(), "è¾“å‡ºåŒ…å«NaN"
                assert not torch.isinf(logits).any(), "è¾“å‡ºåŒ…å«Inf"
                
                # æ£€æŸ¥softmaxæ¦‚ç‡
                probs = torch.softmax(logits, dim=1)
                assert torch.allclose(probs.sum(dim=1), torch.ones(batch_size), atol=1e-6), "æ¦‚ç‡ä¸ä¸º1"
                
                results[model_name][config_name] = {
                    'success': True,
                    'output_shape': logits.shape,
                    'max_prob': probs.max().item(),
                    'min_prob': probs.min().item()
                }
                
                print(f"    âœ“ æˆåŠŸ! è¾“å‡ºå½¢çŠ¶: {logits.shape}")
                
            except Exception as e:
                print(f"    âœ— å¤±è´¥: {e}")
                results[model_name][config_name] = {
                    'success': False,
                    'error': str(e)
                }
    
    # æ‰“å°æµ‹è¯•ç»“æœæ‘˜è¦
    print(f"\n=== æµ‹è¯•ç»“æœæ‘˜è¦ ===")
    
    for model_name, model_results in results.items():
        print(f"\n{model_name} SDE:")
        for config_name, result in model_results.items():
            status = "âœ“" if result['success'] else "âœ—"
            print(f"  {config_name:15s}: {status}")
            if not result['success']:
                print(f"    é”™è¯¯: {result['error']}")
    
    # ç»Ÿè®¡æˆåŠŸç‡
    total_tests = sum(len(model_results) for model_results in results.values())
    successful_tests = sum(
        sum(1 for result in model_results.values() if result['success'])
        for model_results in results.values()
    )
    
    print(f"\næ€»ä½“æˆåŠŸç‡: {successful_tests}/{total_tests} ({100*successful_tests/total_tests:.1f}%)")
    
    return results

def test_consistency():
    """æµ‹è¯•æ¨¡å‹ä¸€è‡´æ€§ - ç¡®ä¿ç›¸åŒé…ç½®äº§ç”Ÿç›¸åŒè¾“å‡ºå½¢çŠ¶"""
    print("\n=== æ¨¡å‹ä¸€è‡´æ€§æµ‹è¯• ===")
    
    batch_size = 2
    seq_len = 50
    input_dim = 3
    num_classes = 7
    
    time_series = torch.randn(batch_size, seq_len, input_dim)
    time_series[:, :, 0] = torch.sort(torch.rand(batch_size, seq_len), dim=1)[0]
    mask = torch.ones(batch_size, seq_len, dtype=torch.bool)
    
    # æµ‹è¯•ç›¸åŒé…ç½®ä¸‹çš„è¾“å‡ºä¸€è‡´æ€§
    config = {
        'input_dim': input_dim,
        'num_classes': num_classes,
        'hidden_channels': 32,
        'contiformer_dim': 64,
        'use_sde': True,
        'use_contiformer': True,
        'use_cga': False
    }
    
    models = {
        'Langevin': LangevinSDEContiformer(**config),
        'LinearNoise': LinearNoiseSDEContiformer(**config),
        'Geometric': GeometricSDEContiformer(**config)
    }
    
    outputs = {}
    for name, model in models.items():
        model.eval()
        with torch.no_grad():
            logits = model(time_series, mask)
        outputs[name] = logits
        print(f"{name:12s}: {logits.shape}, èŒƒå›´: [{logits.min():.3f}, {logits.max():.3f}]")
    
    # éªŒè¯æ‰€æœ‰è¾“å‡ºå½¢çŠ¶ç›¸åŒ
    shapes = [output.shape for output in outputs.values()]
    assert all(shape == shapes[0] for shape in shapes), f"è¾“å‡ºå½¢çŠ¶ä¸ä¸€è‡´: {shapes}"
    
    print("âœ“ æ‰€æœ‰æ¨¡å‹è¾“å‡ºå½¢çŠ¶ä¸€è‡´")

if __name__ == "__main__":
    try:
        # è¿è¡Œæµ‹è¯•
        results = test_model_integration()
        test_consistency()
        
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆ!")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()