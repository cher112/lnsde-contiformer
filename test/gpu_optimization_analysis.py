#!/usr/bin/env python3
"""
GPUä½¿ç”¨ç‡ä¼˜åŒ–åˆ†æå’Œè§£å†³æ–¹æ¡ˆ
"""

import torch
import time
import psutil
from torch.profiler import profile, record_function, ProfilerActivity

def analyze_gpu_bottlenecks():
    """åˆ†æGPUä½¿ç”¨ç‡ç“¶é¢ˆ"""
    print("="*60)
    print("GPUä½¿ç”¨ç‡ç“¶é¢ˆåˆ†æ")
    print("="*60)
    
    # GPUä¿¡æ¯
    if torch.cuda.is_available():
        gpu = torch.cuda.get_device_properties(0)
        allocated = torch.cuda.memory_allocated() / 1024**3
        reserved = torch.cuda.memory_reserved() / 1024**3
        total = gpu.total_memory / 1024**3
        
        print(f"GPUå‹å·: {gpu.name}")
        print(f"å†…å­˜: {allocated:.1f}GB/{total:.1f}GB (ä½¿ç”¨{allocated/total*100:.1f}%)")
        print(f"ç¼“å­˜: {reserved:.1f}GB")
        print(f"è®¡ç®—èƒ½åŠ›: {gpu.major}.{gpu.minor}")
        print(f"å¤šå¤„ç†å™¨: {gpu.multi_processor_count}")
        
        # å†…å­˜åˆ©ç”¨ç‡åˆ†æ
        memory_util = allocated / total * 100
        if memory_util < 70:
            print(f"ğŸ” å†…å­˜åˆ©ç”¨ç‡ä½ ({memory_util:.1f}%) - å¯ä»¥å¢å¤§æ‰¹æ¬¡å¤§å°")
        elif memory_util > 90:
            print(f"âš ï¸ å†…å­˜æ¥è¿‘æ»¡è½½ ({memory_util:.1f}%) - éœ€è¦å†…å­˜ä¼˜åŒ–")
        else:
            print(f"âœ… å†…å­˜åˆ©ç”¨é€‚ä¸­ ({memory_util:.1f}%)")
    
    # CPUåˆ†æ
    cpu_count = psutil.cpu_count()
    memory = psutil.virtual_memory()
    print(f"\nCPUæ ¸å¿ƒ: {cpu_count}")
    print(f"ç³»ç»Ÿå†…å­˜: {memory.used/1024**3:.1f}GB/{memory.total/1024**3:.1f}GB")


def gpu_optimization_strategies():
    """GPUä½¿ç”¨ç‡ä¼˜åŒ–ç­–ç•¥"""
    print("\n" + "="*60)
    print("GPUä½¿ç”¨ç‡ä¼˜åŒ–ç­–ç•¥")
    print("="*60)
    
    print("\n1. ğŸš€ æ‰¹æ¬¡å¤§å°ä¼˜åŒ–")
    print("   å½“å‰å¯èƒ½é—®é¢˜: batch_sizeè¿‡å°ï¼ŒGPUæœªå……åˆ†åˆ©ç”¨")
    print("   è§£å†³æ–¹æ¡ˆ:")
    print("   - åŠ¨æ€æ‰¹æ¬¡å¤§å°: æ ¹æ®å†…å­˜è‡ªåŠ¨è°ƒæ•´")
    print("   - æ¢¯åº¦ç´¯ç§¯: æ¨¡æ‹Ÿæ›´å¤§æ‰¹æ¬¡è€Œä¸è¶…å‡ºå†…å­˜")
    print("   - å»ºè®®æµ‹è¯•: batch_size=32,64,128")
    
    print("\n2. âš¡ æ•°æ®åŠ è½½ä¼˜åŒ–")
    print("   å½“å‰å¯èƒ½é—®é¢˜: CPUæ•°æ®é¢„å¤„ç†æˆä¸ºç“¶é¢ˆ")
    print("   è§£å†³æ–¹æ¡ˆ:")
    print("   - å¢åŠ DataLoader workers")
    print("   - å¯ç”¨pin_memory")
    print("   - æ•°æ®é¢„ç¼“å­˜åˆ°GPU")
    print("   - å¼‚æ­¥æ•°æ®ä¼ è¾“")
    
    print("\n3. ğŸ”§ è®¡ç®—ä¼˜åŒ–")
    print("   å½“å‰å¯èƒ½é—®é¢˜: SDEæ±‚è§£ä¸²è¡Œè®¡ç®—")
    print("   è§£å†³æ–¹æ¡ˆ:")
    print("   - å‘é‡åŒ–SDEæ±‚è§£")
    print("   - å¹¶è¡ŒContiFormerå±‚")
    print("   - å¯ç”¨cudNNåŸºå‡†æ¨¡å¼")
    print("   - ä¼˜åŒ–attentionè®¡ç®—")
    
    print("\n4. ğŸ’¾ å†…å­˜ä¼˜åŒ–")
    print("   å½“å‰å¯èƒ½é—®é¢˜: å†…å­˜ç¢ç‰‡å’Œé‡Šæ”¾ä¸åŠæ—¶")
    print("   è§£å†³æ–¹æ¡ˆ:")
    print("   - æ¢¯åº¦æ£€æŸ¥ç‚¹")
    print("   - æ¿€æ´»é‡è®¡ç®—")
    print("   - åŠæ—¶æ¸…ç†ä¸­é—´å˜é‡")
    print("   - æ··åˆç²¾åº¦è®­ç»ƒ")


def create_optimized_config():
    """åˆ›å»ºGPUä¼˜åŒ–é…ç½®"""
    print("\n" + "="*60)
    print("GPUä¼˜åŒ–é…ç½®å»ºè®®")
    print("="*60)
    
    # RTX 4090 ä¼˜åŒ–é…ç½®
    rtx4090_configs = [
        {
            'name': 'é«˜ååé‡é…ç½®',
            'batch_size': 64,
            'num_workers': 8,
            'pin_memory': True,
            'gradient_accumulation_steps': 1,
            'use_amp': True,
            'torch_compile': True,
            'expected_gpu_util': '70-85%'
        },
        {
            'name': 'å†…å­˜å¹³è¡¡é…ç½®', 
            'batch_size': 32,
            'num_workers': 6,
            'pin_memory': True,
            'gradient_accumulation_steps': 2,
            'use_amp': True,
            'torch_compile': False,
            'expected_gpu_util': '60-75%'
        },
        {
            'name': 'ç¨³å®šæ€§ä¼˜å…ˆé…ç½®',
            'batch_size': 16,
            'num_workers': 4,
            'pin_memory': True,
            'gradient_accumulation_steps': 4,
            'use_amp': True,
            'torch_compile': False,
            'expected_gpu_util': '50-65%'
        }
    ]
    
    for config in rtx4090_configs:
        print(f"\nğŸ“‹ {config['name']}:")
        print(f"   æ‰¹æ¬¡å¤§å°: {config['batch_size']}")
        print(f"   æ•°æ®åŠ è½½è¿›ç¨‹: {config['num_workers']}")
        print(f"   æ¢¯åº¦ç´¯ç§¯: {config['gradient_accumulation_steps']}")
        print(f"   æ··åˆç²¾åº¦: {config['use_amp']}")
        print(f"   é¢„æœŸGPUåˆ©ç”¨ç‡: {config['expected_gpu_util']}")
        
        # ç”Ÿæˆå‘½ä»¤
        cmd = f"""python main.py \\
  --dataset MACHO \\
  --batch_size {config['batch_size']} \\
  --num_workers {config['num_workers']} \\
  --gradient_accumulation_steps {config['gradient_accumulation_steps']} \\
  {'--amp' if config['use_amp'] else '--no_amp'} \\
  {'--torch_compile' if config.get('torch_compile', False) else ''} \\
  --learning_rate 1e-5 \\
  --gradient_clip 1.0 \\
  --epochs 3"""
        
        print(f"   å‘½ä»¤: {cmd}")


def benchmark_batch_sizes():
    """æ‰¹æ¬¡å¤§å°æ€§èƒ½æµ‹è¯•"""
    print("\n" + "="*60)
    print("æ‰¹æ¬¡å¤§å°æ€§èƒ½åŸºå‡†æµ‹è¯•")
    print("="*60)
    
    test_script = '''
import torch
import time
from torch.cuda.amp import autocast

# æ¨¡æ‹Ÿæ¨¡å‹å‰å‘ä¼ æ’­
def benchmark_forward(batch_size, seq_len=200, hidden_dim=128):
    device = torch.device('cuda')
    
    # æ¨¡æ‹Ÿè¾“å…¥
    x = torch.randn(batch_size, seq_len, 3, device=device)
    mask = torch.ones(batch_size, seq_len, device=device)
    
    # æ¨¡æ‹Ÿå¤æ‚è®¡ç®—
    with autocast():
        # ContiFormer attention
        attn_weights = torch.matmul(x, x.transpose(-2, -1)) / (hidden_dim ** 0.5)
        attn_output = torch.matmul(attn_weights, x)
        
        # SDEæ±‚è§£æ¨¡æ‹Ÿ
        dt = 0.01
        steps = 10
        y = x
        for _ in range(steps):
            dy = torch.randn_like(y) * dt
            y = y + dy
        
        output = torch.mean(y, dim=1)
    
    return output

# æµ‹è¯•ä¸åŒæ‰¹æ¬¡å¤§å°
batch_sizes = [8, 16, 32, 64, 128]
results = []

for bs in batch_sizes:
    try:
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
        
        start_time = time.time()
        start_memory = torch.cuda.memory_allocated()
        
        # å¤šæ¬¡è¿è¡Œå–å¹³å‡
        for _ in range(5):
            output = benchmark_forward(bs)
            torch.cuda.synchronize()
        
        end_time = time.time()
        end_memory = torch.cuda.memory_allocated()
        
        avg_time = (end_time - start_time) / 5
        memory_used = (end_memory - start_memory) / 1024**2  # MB
        throughput = bs / avg_time  # samples/sec
        
        results.append({
            'batch_size': bs,
            'time_per_batch': avg_time,
            'memory_mb': memory_used,
            'throughput': throughput
        })
        
        print(f"Batch {bs:3d}: {avg_time:.3f}s, {memory_used:4.0f}MB, {throughput:5.1f} samples/s")
        
    except torch.cuda.OutOfMemoryError:
        print(f"Batch {bs:3d}: OOM")
        break
    except Exception as e:
        print(f"Batch {bs:3d}: Error - {e}")

# æ‰¾æœ€ä¼˜æ‰¹æ¬¡å¤§å°
if results:
    best = max(results, key=lambda x: x['throughput'])
    print(f"\\næœ€ä¼˜æ‰¹æ¬¡å¤§å°: {best['batch_size']} (ååé‡: {best['throughput']:.1f} samples/s)")
'''
    
    print("è¿è¡ŒåŸºå‡†æµ‹è¯•:")
    print("python -c \"")
    for line in test_script.strip().split('\n'):
        print(line)
    print("\"")


if __name__ == "__main__":
    analyze_gpu_bottlenecks()
    gpu_optimization_strategies()
    create_optimized_config()
    benchmark_batch_sizes()