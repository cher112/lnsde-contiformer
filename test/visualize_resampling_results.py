#!/usr/bin/env python3
"""
å¯è§†åŒ–é‡é‡‡æ ·æ•ˆæœ - å±•ç¤ºåˆæˆæ›²çº¿ä¸æºæ ·æœ¬å¯¹æ¯”
"""

import os
import sys
import numpy as np
import torch
import pickle
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
from collections import Counter

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append('/root/autodl-tmp/lnsde-contiformer')

from utils.resampling import configure_chinese_font

# é…ç½®ä¸­æ–‡å­—ä½“
configure_chinese_font()

def load_original_and_resampled_data(dataset_name):
    """åŠ è½½åŸå§‹å’Œé‡é‡‡æ ·æ•°æ®"""
    data_dir = '/root/autodl-fs/lnsde-contiformer/data'
    
    # åŠ è½½åŸå§‹æ•°æ®
    original_path = os.path.join(data_dir, f'{dataset_name}_original.pkl')
    with open(original_path, 'rb') as f:
        original_data = pickle.load(f)
    
    # è½¬æ¢åŸå§‹æ•°æ®æ ¼å¼
    if isinstance(original_data, list):
        n_samples = len(original_data)
        seq_len = len(original_data[0]['time'])
        n_features = 3
        
        X_orig = np.zeros((n_samples, seq_len, n_features))
        y_orig = np.zeros(n_samples, dtype=int)
        
        for i, sample in enumerate(original_data):
            X_orig[i, :, 0] = sample['time']
            X_orig[i, :, 1] = sample['mag'] 
            X_orig[i, :, 2] = sample['errmag']
            y_orig[i] = sample['label']
    
    # åŠ è½½é‡é‡‡æ ·æ•°æ®
    resampled_path = os.path.join(data_dir, f'{dataset_name}_resampled.pkl')
    with open(resampled_path, 'rb') as f:
        resampled_data = pickle.load(f)
    
    X_resampled = resampled_data['X']
    y_resampled = resampled_data['y']
    
    # è½¬æ¢ä¸ºnumpyæ•°ç»„
    if torch.is_tensor(X_resampled):
        X_resampled = X_resampled.cpu().numpy()
    if torch.is_tensor(y_resampled):
        y_resampled = y_resampled.cpu().numpy()
    
    return X_orig, y_orig, X_resampled, y_resampled

def find_synthetic_samples(X_orig, y_orig, X_resampled, y_resampled):
    """è¯†åˆ«åˆæˆæ ·æœ¬ï¼ˆé‡é‡‡æ ·æ•°æ®ä¸­è¶…å‡ºåŸå§‹æ•°æ®é‡çš„éƒ¨åˆ†ï¼‰"""
    original_counts = Counter(y_orig)
    synthetic_indices = {}
    
    current_idx = 0
    for cls in sorted(set(y_resampled)):
        # æ‰¾åˆ°å½“å‰ç±»åˆ«åœ¨é‡é‡‡æ ·æ•°æ®ä¸­çš„ç´¢å¼•
        cls_indices = np.where(y_resampled == cls)[0]
        
        # åŸå§‹æ•°æ®ä¸­è¿™ä¸ªç±»åˆ«æœ‰å¤šå°‘æ ·æœ¬
        original_count = original_counts.get(cls, 0)
        
        # åˆæˆæ ·æœ¬å°±æ˜¯è¶…å‡ºåŸå§‹æ•°é‡çš„é‚£äº›
        if len(cls_indices) > original_count:
            synthetic_indices[cls] = cls_indices[original_count:]
        
    return synthetic_indices

def visualize_synthesis_comparison(dataset_name, save_dir='/root/autodl-tmp/lnsde-contiformer/results/pics'):
    """å¯è§†åŒ–åˆæˆæ ·æœ¬ä¸åŸå§‹æ ·æœ¬å¯¹æ¯”"""
    print(f"ğŸ¨ ç”Ÿæˆ {dataset_name} æ•°æ®é›†çš„åˆæˆæ•ˆæœå¯è§†åŒ–...")
    
    # åŠ è½½æ•°æ®
    X_orig, y_orig, X_resampled, y_resampled = load_original_and_resampled_data(dataset_name)
    
    # æ‰¾åˆ°åˆæˆæ ·æœ¬
    synthetic_indices = find_synthetic_samples(X_orig, y_orig, X_resampled, y_resampled)
    
    # ç»Ÿè®¡ä¿¡æ¯
    original_counts = Counter(y_orig)
    resampled_counts = Counter(y_resampled)
    
    print(f"ğŸ“Š {dataset_name} æ•°æ®ç»Ÿè®¡:")
    print(f"   åŸå§‹åˆ†å¸ƒ: {dict(original_counts)}")
    print(f"   é‡é‡‡æ ·åˆ†å¸ƒ: {dict(resampled_counts)}")
    
    # åˆ›å»ºä¿å­˜ç›®å½•
    dataset_save_dir = os.path.join(save_dir, dataset_name)
    os.makedirs(dataset_save_dir, exist_ok=True)
    
    # é€‰æ‹©è¦å¯è§†åŒ–çš„ç±»åˆ«ï¼ˆé€‰æ‹©æœ‰åˆæˆæ ·æœ¬çš„ç±»åˆ«ï¼‰
    classes_to_visualize = list(synthetic_indices.keys())[:4]  # æœ€å¤š4ä¸ªç±»åˆ«
    
    if not classes_to_visualize:
        print(f"âš ï¸ {dataset_name} æ²¡æœ‰æ‰¾åˆ°åˆæˆæ ·æœ¬")
        return
    
    # åˆ›å»ºå­å›¾
    n_classes = len(classes_to_visualize)
    n_examples = 3  # æ¯ä¸ªç±»åˆ«æ˜¾ç¤º3ä¸ªå¯¹æ¯”ä¾‹å­
    
    fig, axes = plt.subplots(n_classes, n_examples, figsize=(n_examples*5, n_classes*4))
    if n_classes == 1:
        axes = axes.reshape(1, -1)
    if n_examples == 1:
        axes = axes.reshape(-1, 1)
    
    colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FECA57', '#FF9FF3']
    
    for cls_idx, cls in enumerate(classes_to_visualize):
        # è·å–åŸå§‹æ ·æœ¬ï¼ˆè¿™ä¸ªç±»åˆ«çš„å‰å‡ ä¸ªï¼‰
        orig_cls_indices = np.where(y_orig == cls)[0]
        
        # è·å–åˆæˆæ ·æœ¬ç´¢å¼•
        synth_indices = synthetic_indices[cls]
        
        for ex_idx in range(min(n_examples, len(synth_indices))):
            ax = axes[cls_idx, ex_idx] if n_classes > 1 else axes[ex_idx]
            
            # éšæœºé€‰æ‹©ä¸€ä¸ªåŸå§‹æ ·æœ¬å’Œä¸€ä¸ªåˆæˆæ ·æœ¬
            if len(orig_cls_indices) > 0:
                orig_idx = np.random.choice(orig_cls_indices)
                orig_sample = X_orig[orig_idx]
            else:
                continue
                
            synth_idx = synth_indices[ex_idx % len(synth_indices)]
            synth_sample = X_resampled[synth_idx]
            
            # ç»˜åˆ¶æ—¶é—´åºåˆ—ï¼ˆåªæ˜¾ç¤ºmagnitudeç‰¹å¾ï¼‰
            seq_len = min(len(orig_sample), len(synth_sample))
            t = np.linspace(0, 1, seq_len)
            
            # åŸå§‹æ ·æœ¬
            ax.plot(t, orig_sample[:seq_len, 1], 'o-', alpha=0.8, linewidth=2, 
                   color=colors[0], label='åŸå§‹æ ·æœ¬', markersize=3)
            
            # åˆæˆæ ·æœ¬
            ax.plot(t, synth_sample[:seq_len, 1], '^-', linewidth=2, 
                   color=colors[2], label='GPUåˆæˆæ ·æœ¬', markersize=4, alpha=0.9)
            
            # è®¾ç½®æ ‡é¢˜å’Œæ ‡ç­¾
            ax.set_title(f'{dataset_name} - ç±»åˆ«{cls} - æ ·æœ¬{ex_idx+1}\\nGPUæ··åˆæ¨¡å¼åˆæˆ', 
                        fontsize=12, fontweight='bold')
            ax.set_xlabel('æ—¶é—´æ­¥')
            ax.set_ylabel('æ˜Ÿç­‰ (Magnitude)')
            ax.grid(True, alpha=0.3)
            ax.legend(fontsize=10)
            
            # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
            orig_std = np.std(orig_sample[:, 1])
            synth_std = np.std(synth_sample[:, 1])
            orig_mean = np.mean(orig_sample[:, 1])
            synth_mean = np.mean(synth_sample[:, 1])
            
            stats_text = f'åŸå§‹: Î¼={orig_mean:.3f}, Ïƒ={orig_std:.3f}\\nåˆæˆ: Î¼={synth_mean:.3f}, Ïƒ={synth_std:.3f}'
            ax.text(0.02, 0.98, stats_text, 
                   transform=ax.transAxes, va='top', ha='left', 
                   bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.7),
                   fontsize=9)
    
    # æ€»æ ‡é¢˜
    plt.suptitle(f'{dataset_name} æ•°æ®é›† GPUåŠ é€Ÿæ··åˆé‡é‡‡æ ·æ•ˆæœå¯¹æ¯”\\n'
                f'åŸå§‹: {len(y_orig):,}æ ·æœ¬ â†’ é‡é‡‡æ ·: {len(y_resampled):,}æ ·æœ¬ '
                f'(+{len(y_resampled)-len(y_orig):,})', 
                fontsize=16, fontweight='bold')
    plt.tight_layout()
    
    # ä¿å­˜å›¾ç‰‡
    save_path = os.path.join(dataset_save_dir, f'{dataset_name}_gpu_synthesis_comparison.png')
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.show()
    
    print(f"ğŸ’¾ {dataset_name} åˆæˆå¯¹æ¯”å›¾å·²ä¿å­˜è‡³: {save_path}")
    return save_path

def create_distribution_comparison(dataset_name, save_dir='/root/autodl-tmp/lnsde-contiformer/results/pics'):
    """åˆ›å»ºç±»åˆ«åˆ†å¸ƒå¯¹æ¯”å›¾"""
    print(f"ğŸ“Š ç”Ÿæˆ {dataset_name} ç±»åˆ«åˆ†å¸ƒå¯¹æ¯”å›¾...")
    
    # åŠ è½½æ•°æ®
    X_orig, y_orig, X_resampled, y_resampled = load_original_and_resampled_data(dataset_name)
    
    # ç»Ÿè®¡åˆ†å¸ƒ
    original_counts = Counter(y_orig)
    resampled_counts = Counter(y_resampled)
    
    # åˆ›å»ºå¯¹æ¯”å›¾
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
    
    # åŸå§‹åˆ†å¸ƒ
    classes = sorted(set(list(original_counts.keys()) + list(resampled_counts.keys())))
    orig_values = [original_counts.get(cls, 0) for cls in classes]
    resampled_values = [resampled_counts.get(cls, 0) for cls in classes]
    
    x_pos = np.arange(len(classes))
    
    # åŸå§‹åˆ†å¸ƒæŸ±çŠ¶å›¾
    bars1 = ax1.bar(x_pos, orig_values, color='#FF6B6B', alpha=0.8, edgecolor='black')
    ax1.set_title(f'{dataset_name} åŸå§‹ç±»åˆ«åˆ†å¸ƒ\\næ€»æ ·æœ¬: {sum(orig_values):,}', 
                 fontsize=14, fontweight='bold')
    ax1.set_xlabel('ç±»åˆ«', fontsize=12)
    ax1.set_ylabel('æ ·æœ¬æ•°', fontsize=12)
    ax1.set_xticks(x_pos)
    ax1.set_xticklabels([f'ç±»åˆ«{cls}' for cls in classes])
    ax1.grid(axis='y', alpha=0.3)
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for bar, value in zip(bars1, orig_values):
        height = bar.get_height()
        ax1.text(bar.get_x() + bar.get_width()/2., height,
                f'{int(value)}', ha='center', va='bottom', fontsize=10)
    
    # é‡é‡‡æ ·åˆ†å¸ƒæŸ±çŠ¶å›¾
    bars2 = ax2.bar(x_pos, resampled_values, color='#4ECDC4', alpha=0.8, edgecolor='black')
    ax2.set_title(f'{dataset_name} GPUé‡é‡‡æ ·ååˆ†å¸ƒ\\næ€»æ ·æœ¬: {sum(resampled_values):,} '
                 f'(+{sum(resampled_values)-sum(orig_values):,})', 
                 fontsize=14, fontweight='bold')
    ax2.set_xlabel('ç±»åˆ«', fontsize=12)
    ax2.set_ylabel('æ ·æœ¬æ•°', fontsize=12)
    ax2.set_xticks(x_pos)
    ax2.set_xticklabels([f'ç±»åˆ«{cls}' for cls in classes])
    ax2.grid(axis='y', alpha=0.3)
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for bar, value in zip(bars2, resampled_values):
        height = bar.get_height()
        ax2.text(bar.get_x() + bar.get_width()/2., height,
                f'{int(value)}', ha='center', va='bottom', fontsize=10)
    
    # è®¡ç®—ä¸å¹³è¡¡ç‡
    if min(orig_values) > 0:
        orig_imbalance = max(orig_values) / min(orig_values)
    else:
        orig_imbalance = float('inf')
        
    if min(resampled_values) > 0:
        resampled_imbalance = max(resampled_values) / min(resampled_values)
    else:
        resampled_imbalance = float('inf')
    
    # æ·»åŠ ä¸å¹³è¡¡ç‡ä¿¡æ¯
    ax1.text(0.5, 0.95, f'ä¸å¹³è¡¡ç‡: {orig_imbalance:.2f}',
            transform=ax1.transAxes, ha='center', va='top',
            bbox=dict(boxstyle='round', facecolor='lightcoral', alpha=0.7))
    
    ax2.text(0.5, 0.95, f'ä¸å¹³è¡¡ç‡: {resampled_imbalance:.2f}',
            transform=ax2.transAxes, ha='center', va='top',
            bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.7))
    
    plt.suptitle(f'{dataset_name} GPUåŠ é€Ÿæ··åˆé‡é‡‡æ · - ç±»åˆ«åˆ†å¸ƒå¯¹æ¯”', 
                fontsize=16, fontweight='bold')
    plt.tight_layout()
    
    # ä¿å­˜å›¾ç‰‡
    dataset_save_dir = os.path.join(save_dir, dataset_name)
    os.makedirs(dataset_save_dir, exist_ok=True)
    save_path = os.path.join(dataset_save_dir, f'{dataset_name}_distribution_comparison.png')
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.show()
    
    print(f"ğŸ’¾ {dataset_name} åˆ†å¸ƒå¯¹æ¯”å›¾å·²ä¿å­˜è‡³: {save_path}")
    return save_path

def visualize_all_datasets():
    """ä¸ºæ‰€æœ‰æ•°æ®é›†ç”Ÿæˆå¯è§†åŒ–"""
    datasets = ['ASAS', 'LINEAR', 'MACHO']
    
    print("ğŸ¨ å¼€å§‹ç”Ÿæˆæ‰€æœ‰æ•°æ®é›†çš„å¯è§†åŒ–...")
    print("="*60)
    
    for dataset in datasets:
        try:
            print(f"\nğŸ”„ å¤„ç† {dataset} æ•°æ®é›†...")
            
            # ç”Ÿæˆåˆæˆæ ·æœ¬å¯¹æ¯”å›¾
            synthesis_path = visualize_synthesis_comparison(dataset)
            
            # ç”Ÿæˆåˆ†å¸ƒå¯¹æ¯”å›¾
            distribution_path = create_distribution_comparison(dataset)
            
            print(f"âœ… {dataset} å¯è§†åŒ–å®Œæˆ!")
            
        except Exception as e:
            print(f"âŒ {dataset} å¯è§†åŒ–å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    print("\n" + "="*60)
    print("ğŸ‰ æ‰€æœ‰æ•°æ®é›†å¯è§†åŒ–å®Œæˆï¼")
    print("ğŸ“ å›¾ç‰‡ä¿å­˜ä½ç½®: /root/autodl-tmp/lnsde-contiformer/results/pics/")

if __name__ == "__main__":
    visualize_all_datasets()