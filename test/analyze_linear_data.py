#!/usr/bin/env python3
"""
åˆ†æžLINEARæ•°æ®é›†ç»“æž„ï¼Œä¸ºç‰©ç†çº¦æŸTimeGANä¼˜åŒ–åšå‡†å¤‡
é‡ç‚¹åˆ†æžç±»åˆ«1å’Œ2çš„ç‰¹å¾ï¼Œä»¥ä¾¿é’ˆå¯¹æ€§åœ°ç”ŸæˆåŒºåˆ†æ€§å¼ºçš„åˆæˆæ•°æ®
"""

import pickle
import numpy as np
import matplotlib.pyplot as plt
from collections import Counter
import seaborn as sns

def analyze_linear_data():
    """åˆ†æžLINEARæ•°æ®é›†çš„ç»“æž„å’Œç±»åˆ«åˆ†å¸ƒ"""
    print("ðŸ” åˆ†æžLINEARæ•°æ®é›†...")
    
    # åŠ è½½æ•°æ®
    data_path = '/root/autodl-fs/lnsde-contiformer/data/LINEAR_original.pkl'
    with open(data_path, 'rb') as f:
        data = pickle.load(f)
    
    print(f"æ€»æ ·æœ¬æ•°: {len(data)}")
    
    # æ£€æŸ¥ç¬¬ä¸€ä¸ªæ ·æœ¬çš„ç»“æž„
    sample = data[0]
    print(f"æ ·æœ¬å­—æ®µ: {list(sample.keys())}")
    
    # åˆ†æžç±»åˆ«åˆ†å¸ƒ
    labels = [item['label'] for item in data]
    class_names = [item['class_name'] for item in data]
    
    label_counts = Counter(labels)
    class_name_counts = Counter(class_names)
    
    print(f"\nðŸ“Š ç±»åˆ«åˆ†å¸ƒï¼ˆæŒ‰æ ‡ç­¾ï¼‰:")
    for label, count in sorted(label_counts.items()):
        print(f"  ç±»åˆ« {label}: {count} æ ·æœ¬")
    
    print(f"\nðŸ“Š ç±»åˆ«åˆ†å¸ƒï¼ˆæŒ‰åç§°ï¼‰:")
    for name, count in sorted(class_name_counts.items()):
        print(f"  {name}: {count} æ ·æœ¬")
    
    # ç‰¹åˆ«åˆ†æžç±»åˆ«1å’Œç±»åˆ«2çš„ç‰¹å¾
    print(f"\nðŸŽ¯ é‡ç‚¹åˆ†æžç±»åˆ«1å’Œç±»åˆ«2...")
    
    class1_samples = [item for item in data if item['label'] == 1]
    class2_samples = [item for item in data if item['label'] == 2]
    
    print(f"ç±»åˆ«1æ ·æœ¬æ•°: {len(class1_samples)}")
    print(f"ç±»åˆ«2æ ·æœ¬æ•°: {len(class2_samples)}")
    
    if class1_samples:
        print(f"ç±»åˆ«1ç±»å: {class1_samples[0]['class_name']}")
    if class2_samples:
        print(f"ç±»åˆ«2ç±»å: {class2_samples[0]['class_name']}")
    
    # åˆ†æžæ—¶é—´åºåˆ—é•¿åº¦åˆ†å¸ƒ
    def analyze_class_features(samples, class_name):
        """åˆ†æžç‰¹å®šç±»åˆ«çš„ç‰¹å¾"""
        print(f"\nðŸ“ˆ {class_name} ç‰¹å¾åˆ†æž:")
        
        lengths = []
        periods = []
        mag_ranges = []
        error_means = []
        
        for sample in samples[:10]:  # åˆ†æžå‰10ä¸ªæ ·æœ¬
            mask = sample['mask'].astype(bool)
            times = sample['time'][mask]
            mags = sample['mag'][mask]
            errors = sample['errmag'][mask]
            
            lengths.append(len(times))
            periods.append(sample['period'])
            mag_ranges.append(mags.max() - mags.min())
            error_means.append(errors.mean())
        
        print(f"  åºåˆ—é•¿åº¦: {np.mean(lengths):.1f} Â± {np.std(lengths):.1f}")
        print(f"  å‘¨æœŸèŒƒå›´: [{np.min(periods):.3f}, {np.max(periods):.3f}]")
        print(f"  æ˜Ÿç­‰å˜åŒ–: {np.mean(mag_ranges):.3f} Â± {np.std(mag_ranges):.3f}")
        print(f"  è¯¯å·®æ°´å¹³: {np.mean(error_means):.4f} Â± {np.std(error_means):.4f}")
        
        return {
            'lengths': lengths,
            'periods': periods, 
            'mag_ranges': mag_ranges,
            'error_means': error_means
        }
    
    class1_features = analyze_class_features(class1_samples, "ç±»åˆ«1")
    class2_features = analyze_class_features(class2_samples, "ç±»åˆ«2")
    
    # åˆ†æžæ‰€æœ‰ç±»åˆ«çš„å…¸åž‹ç‰¹å¾ï¼Œæ‰¾å‡ºæ··æ·†åŽŸå› 
    print(f"\nðŸ” åˆ†æžæ‰€æœ‰ç±»åˆ«ç‰¹å¾å¯¹æ¯”...")
    all_class_features = {}
    
    for label in sorted(label_counts.keys()):
        samples = [item for item in data if item['label'] == label]
        class_name = samples[0]['class_name'] if samples else f"Class_{label}"
        
        periods = [s['period'] for s in samples[:20]]
        mag_ranges = []
        
        for sample in samples[:20]:
            mask = sample['mask'].astype(bool)
            if np.sum(mask) > 0:
                mags = sample['mag'][mask]
                mag_ranges.append(mags.max() - mags.min())
        
        all_class_features[label] = {
            'name': class_name,
            'count': len(samples),
            'period_mean': np.mean(periods) if periods else 0,
            'period_std': np.std(periods) if periods else 0,
            'mag_range_mean': np.mean(mag_ranges) if mag_ranges else 0,
            'mag_range_std': np.std(mag_ranges) if mag_ranges else 0
        }
    
    print(f"{'ç±»åˆ«':<6} {'åç§°':<12} {'æ ·æœ¬æ•°':<8} {'å‘¨æœŸå‡å€¼':<10} {'å‘¨æœŸæ ‡å‡†å·®':<12} {'æ˜Ÿç­‰å˜åŒ–':<10} {'å˜åŒ–æ ‡å‡†å·®':<10}")
    print("-" * 80)
    
    for label, features in all_class_features.items():
        print(f"{label:<6} {features['name']:<12} {features['count']:<8} "
              f"{features['period_mean']:<10.3f} {features['period_std']:<12.3f} "
              f"{features['mag_range_mean']:<10.3f} {features['mag_range_std']:<10.3f}")
    
    return data, all_class_features

def create_linear_timegan_strategy():
    """åŸºäºŽåˆ†æžç»“æžœåˆ¶å®šLINEAR TimeGANç­–ç•¥"""
    print(f"\nðŸŽ¯ åˆ¶å®šLINEAR TimeGANå¢žå¼ºç­–ç•¥...")
    
    strategy = {
        'target_classes': [1, 2],  # é‡ç‚¹ä¼˜åŒ–ç±»åˆ«1å’Œ2
        'physics_constraints': {
            'enhanced_periodicity': 0.3,     # åŠ å¼ºå‘¨æœŸçº¦æŸ
            'noise_reduction': 0.25,         # åŠ å¼ºåŽ»å™ª
            'class_separation': 0.2,         # å¢žåŠ ç±»åˆ«åŒºåˆ†åº¦
            'magnitude_consistency': 0.15    # æ˜Ÿç­‰ä¸€è‡´æ€§
        },
        'generation_params': {
            'batch_size': 64,
            'n_epochs': 200,    # å¢žåŠ è®­ç»ƒè½®æ•°æé«˜è´¨é‡
            'lr': 0.0005       # è¾ƒå°å­¦ä¹ çŽ‡ç¡®ä¿ç¨³å®šæ”¶æ•›
        }
    }
    
    print(f"ç­–ç•¥é…ç½®:")
    print(f"  ç›®æ ‡ç±»åˆ«: {strategy['target_classes']}")
    print(f"  ç‰©ç†çº¦æŸæƒé‡: {strategy['physics_constraints']}")
    print(f"  ç”Ÿæˆå‚æ•°: {strategy['generation_params']}")
    
    return strategy

if __name__ == "__main__":
    data, features = analyze_linear_data()
    strategy = create_linear_timegan_strategy()
    
    print(f"\nâœ… LINEARæ•°æ®é›†åˆ†æžå®Œæˆï¼")
    print(f"ä¸‹ä¸€æ­¥: åº”ç”¨ç‰©ç†çº¦æŸTimeGANç”Ÿæˆé’ˆå¯¹ç±»åˆ«1ã€2ä¼˜åŒ–çš„åˆæˆæ•°æ®")