#!/usr/bin/env python3
"""
GPUä½¿ç”¨ç‡ä¼˜åŒ–å®Œæ•´è§£å†³æ–¹æ¡ˆ
"""

print("="*70)
print("ğŸš€ GPUä½¿ç”¨ç‡ä¼˜åŒ–å®Œæ•´è§£å†³æ–¹æ¡ˆ")
print("="*70)

print("\nğŸ“Š ç°çŠ¶åˆ†æ:")
print("â€¢ å½“å‰GPUä½¿ç”¨ç‡: 9% (ä¸¥é‡ä¸è¶³)")  
print("â€¢ RTX 4090: 24GB VRAM, 128ä¸ªSMå¤„ç†å™¨")
print("â€¢ é—®é¢˜æ ¹æº: SDEè®¡ç®—å›¾æ·±åº¦ + ContiFormeræ³¨æ„åŠ› + å°æ‰¹æ¬¡å¤§å°")

print("\nğŸ¯ ä¼˜åŒ–ç­–ç•¥ç»„åˆ:")

configs = [
    {
        'name': 'ğŸ¥‰ ä¿å®ˆé…ç½® (ç¨³å®šä¼˜å…ˆ)',
        'batch_size': 16,
        'gradient_accumulation_steps': 4,
        'use_gradient_checkpoint': False,
        'amp': True,
        'learning_rate': '1e-5',
        'gradient_clip': '1.0',
        'num_workers': 4,
        'expected_gpu_util': '50-65%',
        'expected_memory': '8-12GB',
        'risk': 'ä½',
        'description': 'æœ€ç¨³å®šï¼Œé€‚åˆè°ƒè¯•å’ŒéªŒè¯'
    },
    {
        'name': 'ğŸ¥ˆ å¹³è¡¡é…ç½® (æ¨è)',
        'batch_size': 24,
        'gradient_accumulation_steps': 3,
        'use_gradient_checkpoint': True,
        'amp': True,
        'learning_rate': '1e-5',
        'gradient_clip': '0.5',
        'num_workers': 6,
        'expected_gpu_util': '70-85%',
        'expected_memory': '14-18GB',
        'risk': 'ä¸­',
        'description': 'æœ€ä½³æ€§èƒ½/ç¨³å®šæ€§å¹³è¡¡'
    },
    {
        'name': 'ğŸ¥‡ æ¿€è¿›é…ç½® (æœ€å¤§åŒ–GPU)',
        'batch_size': 32,
        'gradient_accumulation_steps': 2,
        'use_gradient_checkpoint': True,
        'amp': True,
        'learning_rate': '5e-6',
        'gradient_clip': '0.3',
        'num_workers': 8,
        'expected_gpu_util': '85-95%',
        'expected_memory': '18-22GB',
        'risk': 'é«˜',
        'description': 'æœ€å¤§åŒ–GPUåˆ©ç”¨ç‡ï¼Œå¯èƒ½OOM'
    },
    {
        'name': 'âš¡ æé™é…ç½® (å®éªŒæ€§)',
        'batch_size': 48,
        'gradient_accumulation_steps': 1,
        'use_gradient_checkpoint': True,
        'amp': True,
        'learning_rate': '3e-6',
        'gradient_clip': '0.1',
        'num_workers': 12,
        'expected_gpu_util': '95-100%',
        'expected_memory': '20-24GB',
        'risk': 'æé«˜',
        'description': 'æé™æµ‹è¯•ï¼Œé«˜æ¦‚ç‡OOM'
    }
]

for i, config in enumerate(configs):
    print(f"\n{config['name']}:")
    print(f"   æ‰¹æ¬¡å¤§å°: {config['batch_size']}")
    print(f"   æ¢¯åº¦ç´¯ç§¯: {config['gradient_accumulation_steps']} (ç­‰æ•ˆæ‰¹æ¬¡={config['batch_size']*config['gradient_accumulation_steps']})")
    print(f"   æ¢¯åº¦æ£€æŸ¥ç‚¹: {'âœ…' if config['use_gradient_checkpoint'] else 'âŒ'}")
    print(f"   æ··åˆç²¾åº¦: {'âœ…' if config['amp'] else 'âŒ'}")
    print(f"   å­¦ä¹ ç‡: {config['learning_rate']}")
    print(f"   æ¢¯åº¦è£å‰ª: {config['gradient_clip']}")
    print(f"   æ•°æ®åŠ è½½è¿›ç¨‹: {config['num_workers']}")
    print(f"   é¢„æœŸGPUåˆ©ç”¨ç‡: {config['expected_gpu_util']}")
    print(f"   é¢„æœŸå†…å­˜ä½¿ç”¨: {config['expected_memory']}")
    print(f"   é£é™©ç­‰çº§: {config['risk']}")
    print(f"   è¯´æ˜: {config['description']}")

print("\n" + "="*70)
print("ğŸ› ï¸ å…·ä½“æ‰§è¡Œå‘½ä»¤")
print("="*70)

# ç”Ÿæˆå…·ä½“å‘½ä»¤
for i, config in enumerate(configs):
    print(f"\n{config['name']}:")
    
    cmd_parts = [
        "python main.py \\",
        f"  --dataset MACHO \\",
        f"  --batch_size {config['batch_size']} \\",
        f"  --gradient_accumulation_steps {config['gradient_accumulation_steps']} \\",
        f"  --learning_rate {config['learning_rate']} \\",
        f"  --gradient_clip {config['gradient_clip']} \\",
        f"  --num_workers {config['num_workers']} \\",
    ]
    
    if config['use_gradient_checkpoint']:
        cmd_parts.append("  --use_gradient_checkpoint \\")
    
    if config['amp']:
        cmd_parts.append("  --amp \\")
    
    cmd_parts.extend([
        "  --epochs 3 \\",
        "  --save_best_only"
    ])
    
    for part in cmd_parts:
        print(part)

print("\n" + "="*70)
print("ğŸ“ˆ æ€§èƒ½ç›‘æ§")
print("="*70)

monitor_commands = {
    "å®æ—¶GPUç›‘æ§": "watch -n 1 'nvidia-smi --query-gpu=memory.used,memory.total,utilization.gpu,utilization.memory --format=csv,noheader,nounits'",
    "è¯¦ç»†æ€§èƒ½åˆ†æ": "nvidia-smi dmon -s pucvmet",
    "Pythonå†…å­˜ç›‘æ§": "ps aux | grep python | head -5",
    "ç³»ç»Ÿèµ„æºç›‘æ§": "htop"
}

for name, cmd in monitor_commands.items():
    print(f"\n{name}:")
    print(f"  {cmd}")

print("\n" + "="*70)
print("âš ï¸ é‡è¦æ³¨æ„äº‹é¡¹")
print("="*70)

warnings = [
    "1. ä»ä¿å®ˆé…ç½®å¼€å§‹æµ‹è¯•ï¼Œé€æ­¥å¢åŠ æ‰¹æ¬¡å¤§å°",
    "2. ç›‘æ§GPUå†…å­˜ä½¿ç”¨ï¼Œæ¥è¿‘90%æ—¶åœæ­¢å¢åŠ æ‰¹æ¬¡",
    "3. æ¢¯åº¦æ£€æŸ¥ç‚¹ä¼šå¢åŠ 15-30%è®¡ç®—æ—¶é—´ä½†èŠ‚çœ50-80%å†…å­˜",
    "4. æ··åˆç²¾åº¦è®­ç»ƒå¿…é¡»å¯ç”¨ï¼Œå¯èŠ‚çœ50%å†…å­˜",
    "5. å­¦ä¹ ç‡éœ€è¦æ ¹æ®ç­‰æ•ˆæ‰¹æ¬¡å¤§å°è°ƒæ•´",
    "6. num_workersè¿‡å¤šå¯èƒ½å¯¼è‡´CPUç“¶é¢ˆ",
    "7. OOMæ—¶å‡å°batch_sizeè€Œä¸æ˜¯å…³é—­åŠŸèƒ½"
]

for warning in warnings:
    print(f"  {warning}")

print("\n" + "="*70)
print("ğŸ¯ æ¨èæ‰§è¡Œé¡ºåº")
print("="*70)

steps = [
    "1. ğŸ§ª æµ‹è¯•ä¿å®ˆé…ç½®éªŒè¯åŸºç¡€åŠŸèƒ½",
    "2. ğŸ“Š è¿è¡Œå¹³è¡¡é…ç½®è¿›è¡Œæ­£å¼è®­ç»ƒ", 
    "3. âš¡ å°è¯•æ¿€è¿›é…ç½®æœ€å¤§åŒ–æ€§èƒ½",
    "4. ğŸ” æ ¹æ®å®é™…å†…å­˜ä½¿ç”¨å¾®è°ƒå‚æ•°",
    "5. ğŸ“ˆ æŒç»­ç›‘æ§å¹¶è®°å½•æœ€ä¼˜é…ç½®"
]

for step in steps:
    print(f"  {step}")

print(f"\n{'='*70}")
print("âœ… GPUä¼˜åŒ–æ–¹æ¡ˆå·²å®Œæˆ!")
print("ä»å¹³è¡¡é…ç½®å¼€å§‹ï¼Œé¢„æœŸGPUä½¿ç”¨ç‡å¯è¾¾70-85%ï¼")
print("="*70)