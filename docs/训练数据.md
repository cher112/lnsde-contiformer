

> * 提及不同数据集类别不平衡情况不一样，在更不平衡的效果更好(堆叠图 - 横轴数据集 纵轴堆叠准确度和不平衡度（指标要可解释性）)

## 模型架构详细说明

### 完整模型 (Neural SDE + ContiFormer)
**总参数量**: 约2.5M参数

整体架构：输入 → 特征提取 → Neural SDE → ContiFormer → 分类器

1. **基础特征提取层** (所有模型共享):
   - Conv1d(3, 64, kernel=5) + BatchNorm1d + ReLU
   - Conv1d(64, 128, kernel=3) + BatchNorm1d + ReLU  
   - Conv1d(128, hidden_channels, kernel=3) + BatchNorm1d
   - 作用：将原始光变曲线(time, mag, errmag)转换为深度特征
   - 输出: (batch, seq_len, hidden_channels=128)

2. **Neural SDE模块** (时序动力学建模):
   - **Langevin SDE**: 
     - 漂移网络μ(x,t): Linear(128, 256) → ReLU → Linear(256, 128)
     - 扩散网络σ(x,t): Linear(128, 256) → ReLU → Linear(256, 128) → Softplus
     - 求解方法: Euler-Maruyama
   - **Linear Noise SDE**:
     - 漂移网络μ(x,t): Linear(128, 128)
     - 扩散常数σ: 可学习标量参数
     - 特点：线性漂移，常数扩散
   - **Geometric SDE**:
     - 漂移网络μ(x,t): Linear(128, 256) → ReLU → Linear(256, 128)
     - 扩散系数σ: 可学习标量，与状态成比例
     - 特点：几何布朗运动
   - 输出: (batch, seq_len, hidden_channels=128)

3. **ContiFormer模块** (连续时间注意力):
   - 连续时间位置编码
   - Transformer编码器: 6层，每层包含
     - 多头自注意力: 8头，维度128
     - 时间感知注意力机制
     - 前馈网络: Linear(128, 512) → ReLU → Linear(512, 128)
     - Dropout: 0.1
     - LayerNorm
   - 时间加权全局池化
   - 输出: (batch, 128)

4. **分类头**:
   - Linear(128, 256) + ReLU + Dropout(0.3)
   - Linear(256, 128) + ReLU + Dropout(0.3)
   - Linear(128, num_classes)

### ContiFormer-only模型 (消融实验)
**总参数量**: 约920K参数

架构：输入 → 特征提取 → ContiFormer → 分类器
- 移除Neural SDE模块
- 特征直接输入ContiFormer
- 保留时间感知能力但失去随机动力学建模

### Neural SDE-only模型 (消融实验)
**总参数量**: 约1.6M参数

架构：输入 → 特征提取 → Neural SDE → 全局池化 → 分类器
- 移除ContiFormer模块
- 使用简单全局平均池化替代注意力机制
- 保留随机动力学但失去长程依赖建模

## 实验结果汇总

ASAS 数据集
| 方法                 | 验证准确率        | 验证加权F1    | 验证加权Recall |
| -------------------- | ----------------- | ------------- | -------------- |
| LNSDE+contiformer    | 96.57±1.26%       | 95.33±1.40    | 95.57±1.26     |
| GEOSDE+contiformer   | 93.39±0.26%       | 92.82±0.24    | 93.39±0.26     |
| LANGEVIN+contiformer | 91.09±0.75%       | 89.65±0.90    | 91.09±0.75     |
| ContiformerOnly      | 92.10±1.15%       | 91.00±1.20    | 92.10±1.15     |
| LNSDEOnly            | 57.48±2.30%       | 45.10±2.50    | 57.50±2.30     |
| GEOSDEOnly           | 55.13±2.50%       | 39.18±2.80    | 55.13±2.50     |
| LANGEVINOnly         | 55.13±2.80%       | 39.33±3.00    | 55.13±2.80     |

LINEAR 数据集
| 方法                 | 验证准确率           | 验证加权F1    | 验证加权Recall |
| -------------------- | -------------------- | ------------- | -------------- |
| LNSDE+contiformer    | 89.43±0.49%          | 86.87±0.32    | 89.43±0.14     |
| GEOSDE+contiformer   | 88.41±1.44%          | 85.59±1.90    | 88.41±1.44     |
| LANGEVIN+contiformer | 87.57±1.20%          | 84.50±1.50    | 87.57±1.20     |
| ContiformerOnly      | 83.96±1.80%          | 81.00±2.00    | 83.96±1.80     |
| LNSDEOnly            | 42.75±2.50%          | 28.10±2.80    | 42.70±2.50     |
| GEOSDEOnly           | 32.15±3.50%          | 16.89±2.80    | 32.15±3.50     |
| LANGEVINOnly         | 40.35±2.20%          | 23.20±2.50    | 40.35±2.20     |

MACHO 数据集
| 方法                 | 验证准确率  | 验证加权F1    | 验证加权Recall |
| -------------------- | ----------- | ------------- | -------------- |
| LNSDE+contiformer    | 81.52±2.42% | 80.17±2.45    | 81.52±2.42     |
| GEOSDE+contiformer   | 67.29±8.55% | 62.81±9.99    | 67.29±8.55     |
| LANGEVIN+contiformer | 66.46±0.52% | 63.50±1.80    | 66.46±0.52     |
| ContiformerOnly      | 73.60±2.20% | 71.30±2.30    | 73.60±2.20     |
| LNSDEOnly            | 41.61±3.00% | 30.90±3.20    | 41.60±3.00     |
| GEOSDEOnly           | 34.16±3.20% | 17.40±2.50    | 34.16±3.20     |
| LANGEVINOnly         | 34.16±3.50% | 18.06±2.80    | 34.16±3.50     |

<img src="https://img.chermz112.xyz/i/2025/08/29/lw02v9-0.png" alt="image-20250829132350455" style="zoom:33%;" />

​							图1 准确度vs分类不平衡                               

<img src="https://img.chermz112.xyz/i/2025/08/25/gjo9e3-0.png" alt="image-20250825100047656" style="zoom:33%;" />

<img src="https://img.chermz112.xyz/i/2025/08/25/gk2vvn-0.png" alt="image-20250825100114917" style="zoom:33%;" />



